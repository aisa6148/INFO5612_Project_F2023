{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTUR: Neural News Recommendation with Long- and Short-term User Representations\n",
    "LSTUR \\[1\\] is a news recommendation approach capturing users' both long-term preferences and short-term interests. The core of LSTUR is a news encoder and a user encoder.  In the news encoder, we learn representations of news from their titles. In user encoder, we propose to learn long-term\n",
    "user representations from the embeddings of their IDs. In addition, we propose to learn short-term user representations from their recently browsed news via GRU network. Besides, we propose two methods to combine\n",
    "long-term and short-term user representations. The first one is using the long-term user representation to initialize the hidden state of the GRU network in short-term user representation. The second one is concatenating both\n",
    "long- and short-term user representations as a unified user vector.\n",
    "\n",
    "## Properties of LSTUR:\n",
    "- LSTUR captures users' both long-term and short term preference.\n",
    "- It uses embeddings of users' IDs to learn long-term user representations.\n",
    "- It uses users' recently browsed news via GRU network to learn short-term user representations.\n",
    "\n",
    "## Data format:\n",
    "For quicker training and evaluaiton, we sample MINDdemo dataset of 5k users from [MIND small dataset](https://msnews.github.io/). The MINDdemo dataset has the same file format as MINDsmall and MINDlarge. If you want to try experiments on MINDsmall and MINDlarge, please change the dowload source. Select the MIND_type parameter from ['large', 'small', 'demo'] to choose dataset.\n",
    " \n",
    "**MINDdemo_train** is used for training, and **MINDdemo_dev** is used for evaluation. Training data and evaluation data are composed of a news file and a behaviors file. You can find more detailed data description in [MIND repo](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md)\n",
    "\n",
    "### news data\n",
    "This file contains news information including newsid, category, subcatgory, news title, news abstarct, news url and entities in news title, entities in news abstarct.\n",
    "One simple example: <br>\n",
    "\n",
    "`N46466\tlifestyle\tlifestyleroyals\tThe Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\tShop the notebooks, jackets, and more that the royals can't live without.\thttps://www.msn.com/en-us/lifestyle/lifestyleroyals/the-brands-queen-elizabeth,-prince-charles,-and-prince-philip-swear-by/ss-AAGH0ET?ocid=chopendata\t[{\"Label\": \"Prince Philip, Duke of Edinburgh\", \"Type\": \"P\", \"WikidataId\": \"Q80976\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [48], \"SurfaceForms\": [\"Prince Philip\"]}, {\"Label\": \"Charles, Prince of Wales\", \"Type\": \"P\", \"WikidataId\": \"Q43274\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [28], \"SurfaceForms\": [\"Prince Charles\"]}, {\"Label\": \"Elizabeth II\", \"Type\": \"P\", \"WikidataId\": \"Q9682\", \"Confidence\": 0.97, \"OccurrenceOffsets\": [11], \"SurfaceForms\": [\"Queen Elizabeth\"]}]\t[]`\n",
    "<br>\n",
    "\n",
    "In general, each line in data file represents information of one piece of news: <br>\n",
    "\n",
    "`[News ID] [Category] [Subcategory] [News Title] [News Abstrct] [News Url] [Entities in News Title] [Entities in News Abstract] ...`\n",
    "\n",
    "<br>\n",
    "\n",
    "We generate a word_dict file to tranform words in news title to word indexes, and a embedding matrix is initted from pretrained glove embeddings.\n",
    "\n",
    "### behaviors data\n",
    "One simple example: <br>\n",
    "`1\tU82271\t11/11/2019 3:28:58 PM\tN3130 N11621 N12917 N4574 N12140 N9748\tN13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0`\n",
    "<br>\n",
    "\n",
    "In general, each line in data file represents one instance of an impression. The format is like: <br>\n",
    "\n",
    "`[Impression ID] [User ID] [Impression Time] [User Click History] [Impression News]`\n",
    "\n",
    "<br>\n",
    "\n",
    "User Click History is the user historical clicked news before Impression Time. Impression News is the displayed news in an impression, which format is:<br>\n",
    "\n",
    "`[News ID 1]-[label1] ... [News ID n]-[labeln]`\n",
    "\n",
    "<br>\n",
    "Label represents whether the news is clicked by the user. All information of news in User Click History and Impression News can be found in news data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.12 (main, Apr  5 2022, 01:53:17) \n",
      "[Clang 12.0.0 ]\n",
      "Tensorflow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "from recommenders.models.newsrec.models.lstur import LSTURModel\n",
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "seed = 40\n",
    "batch_size = 32\n",
    "\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17.0k/17.0k [00:03<00:00, 4.92kKB/s]\n",
      "100%|██████████| 9.84k/9.84k [00:01<00:00, 7.98kKB/s]\n",
      "100%|██████████| 95.0k/95.0k [00:12<00:00, 7.73kKB/s]\n"
     ]
    }
   ],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "data_path = tmpdir.name\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
    "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\", r'lstur.yaml')\n",
    "\n",
    "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
    "\n",
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, \\\n",
    "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
    "                               os.path.join(data_path, 'utils'), mind_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'support_quick_scoring': True, 'dropout': 0.2, 'attention_hidden_dim': 200, 'head_num': 4, 'head_dim': 100, 'filter_num': 400, 'window_size': 3, 'vert_emb_dim': 100, 'subvert_emb_dim': 100, 'gru_unit': 400, 'type': 'ini', 'user_emb_dim': 50, 'learning_rate': 0.0001, 'optimizer': 'adam', 'epochs': 5, 'batch_size': 32, 'show_step': 100000, 'title_size': 30, 'his_size': 50, 'data_format': 'news', 'npratio': 4, 'metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'word_emb_dim': 300, 'cnn_activation': 'relu', 'model_type': 'lstur', 'loss': 'cross_entropy_loss', 'wordEmb_file': '/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmpm5ej7ep3/utils/embedding.npy', 'wordDict_file': '/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmpm5ej7ep3/utils/word_dict.pkl', 'userDict_file': '/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmpm5ej7ep3/utils/uid2index.pkl'}\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file, \n",
    "                          wordEmb_file=wordEmb_file,\n",
    "                          wordDict_file=wordDict_file, \n",
    "                          userDict_file=userDict_file,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs)\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = MINDIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the LSTUR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 14:44:00.699947: W tensorflow/c/c_api.cc:300] Operation '{name:'embedding/embeddings/Assign' id:27 op device:{requested: '', assigned: ''} def:{{{node embedding/embeddings/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](embedding/embeddings, embedding/embeddings/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv1d/Relu:0\", shape=(None, 30, 400), dtype=float32)\n",
      "Tensor(\"att_layer2/Sum_1:0\", shape=(None, 400), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aishwaryasatwani/recommenders/recommender_project/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = LSTURModel(hparams, iterator, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/aishwaryasatwani/recommenders/recommender_project/lib/python3.9/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-06 14:44:03.849637: W tensorflow/c/c_api.cc:300] Operation '{name:'conv1d/bias/Assign' id:62 op device:{requested: '', assigned: ''} def:{{{node conv1d/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv1d/bias, conv1d/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "586it [00:09, 62.14it/s]\n",
      "0it [00:00, ?it/s]2023-12-06 14:44:13.105162: W tensorflow/c/c_api.cc:300] Operation '{name:'gru/strided_slice_2' id:958 op device:{requested: '', assigned: ''} def:{{{node gru/strided_slice_2}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, _has_manual_control_dependencies=true, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](gru/TensorArrayV2Stack/TensorListStack, gru/strided_slice_2/stack, gru/strided_slice_2/stack_1, gru/strided_slice_2/stack_2)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "236it [02:42,  1.46it/s]\n",
      "7538it [00:00, 9481.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.5201, 'mean_mrr': 0.2214, 'ndcg@5': 0.2292, 'ndcg@10': 0.2912}\n"
     ]
    }
   ],
   "source": [
    "print(model.run_eval(valid_news_file, valid_behaviors_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2023-11-29 15:39:04.049869: W tensorflow/c/c_api.cc:300] Operation '{name:'loss/mul' id:2061 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/activation_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-29 15:39:04.319160: W tensorflow/c/c_api.cc:300] Operation '{name:'training/Adam/gru/gru_cell/recurrent_kernel/v/Assign' id:2750 op device:{requested: '', assigned: ''} def:{{{node training/Adam/gru/gru_cell/recurrent_kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/gru/gru_cell/recurrent_kernel/v, training/Adam/gru/gru_cell/recurrent_kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "1086it [23:43,  1.31s/it]\n",
      "586it [00:04, 128.78it/s]\n",
      "236it [01:13,  3.23it/s]\n",
      "7538it [00:00, 17471.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 1\n",
      "train info: logloss loss:1.487765562688009\n",
      "eval info: group_auc:0.5924, mean_mrr:0.2564, ndcg@10:0.3438, ndcg@5:0.2809\n",
      "at epoch 1 , train time: 1423.5 eval time: 81.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [22:56,  1.27s/it]\n",
      "586it [00:04, 127.10it/s]\n",
      "236it [01:18,  3.01it/s]\n",
      "7538it [00:00, 16086.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 2\n",
      "train info: logloss loss:1.4049629973004096\n",
      "eval info: group_auc:0.6169, mean_mrr:0.2777, ndcg@10:0.3681, ndcg@5:0.3046\n",
      "at epoch 2 , train time: 1376.5 eval time: 87.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [48:05,  2.66s/it]\n",
      "586it [00:04, 132.57it/s]\n",
      "236it [01:15,  3.12it/s]\n",
      "7538it [00:00, 15095.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 3\n",
      "train info: logloss loss:1.3577124978626631\n",
      "eval info: group_auc:0.6285, mean_mrr:0.2877, ndcg@10:0.3799, ndcg@5:0.3163\n",
      "at epoch 3 , train time: 2885.3 eval time: 84.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [23:03,  1.27s/it]\n",
      "586it [00:04, 129.52it/s]\n",
      "236it [01:17,  3.03it/s]\n",
      "7538it [00:00, 16914.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 4\n",
      "train info: logloss loss:1.320989074188921\n",
      "eval info: group_auc:0.6275, mean_mrr:0.2833, ndcg@10:0.3769, ndcg@5:0.3135\n",
      "at epoch 4 , train time: 1383.6 eval time: 86.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [2:16:19,  7.53s/it] \n",
      "586it [00:04, 129.15it/s]\n",
      "236it [01:14,  3.18it/s]\n",
      "7538it [00:00, 15665.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 5\n",
      "train info: logloss loss:1.2866800133255525\n",
      "eval info: group_auc:0.6424, mean_mrr:0.2949, ndcg@10:0.3901, ndcg@5:0.327\n",
      "at epoch 5 , train time: 8179.2 eval time: 83.0\n",
      "CPU times: user 13h 53min 21s, sys: 12min 55s, total: 14h 6min 16s\n",
      "Wall time: 4h 21min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<recommenders.models.newsrec.models.lstur.LSTURModel at 0x7fa90e391b20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "586it [00:04, 131.36it/s]\n",
      "236it [01:14,  3.17it/s]\n",
      "7538it [00:00, 18118.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.6424, 'mean_mrr': 0.2949, 'ndcg@5': 0.327, 'ndcg@10': 0.3901}\n",
      "CPU times: user 8min 48s, sys: 6.29 s, total: 8min 54s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
    "print(res_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "group_auc": 0.6424,
        "mean_mrr": 0.2949,
        "ndcg@10": 0.3901,
        "ndcg@5": 0.327
       },
       "encoder": "json",
       "name": "res_syn",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "res_syn"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue(\"res_syn\", res_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(data_path, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmprxpytgkb/model'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_path, exist_ok=True)\n",
    "\n",
    "model.model.save_weights(os.path.join(model_path, \"lstur_ckpt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File\n",
    "This code segment is used to generate the prediction.zip file, which is in the same format in [MIND Competition Submission Tutorial](https://competitions.codalab.org/competitions/24122#learn_the_details-submission-guidelines).\n",
    "\n",
    "Please change the `MIND_type` parameter to `large` if you want to submit your prediction to [MIND Competition](https://msnews.github.io/competition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmpm5ej7ep3/valid/behaviors.tsv'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_news_file) # 18723 news\n",
    "valid_behaviors_file # 7538 users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "586it [00:08, 70.38it/s]\n",
      "236it [02:51,  1.37it/s]\n",
      "7538it [00:00, 7911.75it/s]\n"
     ]
    }
   ],
   "source": [
    "group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.train_iterator.uid2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U41827</td>\n",
       "      <td>[N23699, N21291, N1901, N27292, N17443, N18282...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U61881</td>\n",
       "      <td>[N26916, N4641, N25522, N14893, N19035, N3877,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U54180</td>\n",
       "      <td>[N13528, N27689, N10879, N11662, N14409, N6849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U41164</td>\n",
       "      <td>[N20150, N1807, N26916, N28138, N9576, N19737,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U8588</td>\n",
       "      <td>[N21325, N5982, N19737, N9576, N20150, N25701,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>U23841</td>\n",
       "      <td>[N26256, N28117, N2718, N16798, N27689, N6280,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>U28014</td>\n",
       "      <td>[N26670, N12794, N3390, N17443, N27292, N21852...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>U89684</td>\n",
       "      <td>[N17443, N16798, N24553, N26096, N15927, N2625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>U92611</td>\n",
       "      <td>[N14850, N26647, N272, N22751, N21398, N26916,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>U329</td>\n",
       "      <td>[N3560, N3390, N13690, N4939, N25735, N5520, N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                            news_id\n",
       "0     U41827  [N23699, N21291, N1901, N27292, N17443, N18282...\n",
       "1     U61881  [N26916, N4641, N25522, N14893, N19035, N3877,...\n",
       "2     U54180  [N13528, N27689, N10879, N11662, N14409, N6849...\n",
       "3     U41164  [N20150, N1807, N26916, N28138, N9576, N19737,...\n",
       "4      U8588  [N21325, N5982, N19737, N9576, N20150, N25701,...\n",
       "...      ...                                                ...\n",
       "7533  U23841  [N26256, N28117, N2718, N16798, N27689, N6280,...\n",
       "7534  U28014  [N26670, N12794, N3390, N17443, N27292, N21852...\n",
       "7535  U89684  [N17443, N16798, N24553, N26096, N15927, N2625...\n",
       "7536  U92611  [N14850, N26647, N272, N22751, N21398, N26916,...\n",
       "7537    U329  [N3560, N3390, N13690, N4939, N25735, N5520, N...\n",
       "\n",
       "[7538 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = []\n",
    "news_rec_lists = []\n",
    "user_clicks = defaultdict(())\n",
    "with open(valid_behaviors_file, 'r') as rd:\n",
    "        impr_index = 0\n",
    "        for line in rd:\n",
    "            uid, time, history, impr = line.strip(\"\\n\").split('\\t')[-4:]\n",
    "            impr_news = [i.split(\"-\")[0] for i in impr.split()]\n",
    "            click_news = ()\n",
    "            for i in impr.split():\n",
    "                impr_news.append(i.split(\"-\")[0])\n",
    "                if i.split(\"-\")[1] == '1':\n",
    "                    click_news.add(i.split(\"-\")[0])\n",
    "            user_ids.append(uid)\n",
    "            news_rec_lists.append(impr_news)\n",
    "            user_clicks[uid] = click_news\n",
    "user_rec_df = pd.DataFrame({'user_id' : user_ids, 'news_id': news_rec_lists})\n",
    "user_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/aishwaryasatwani/recommenders/examples/00_quick_start/lstur_MIND.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aishwaryasatwani/recommenders/examples/00_quick_start/lstur_MIND.ipynb#Y102sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m             news_rec_lists\u001b[39m.\u001b[39mappend(impr_news)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aishwaryasatwani/recommenders/examples/00_quick_start/lstur_MIND.ipynb#Y102sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             news_rec_imp_train_lists\u001b[39m.\u001b[39mappend(impr_news_click)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aishwaryasatwani/recommenders/examples/00_quick_start/lstur_MIND.ipynb#Y102sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m user_rec_impr_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame({\u001b[39m'\u001b[39;49m\u001b[39muser_id\u001b[39;49m\u001b[39m'\u001b[39;49m : user_train_ids, \u001b[39m'\u001b[39;49m\u001b[39mnews_id\u001b[39;49m\u001b[39m'\u001b[39;49m: news_rec_lists, \u001b[39m'\u001b[39;49m\u001b[39mclick\u001b[39;49m\u001b[39m'\u001b[39;49m : impr_news_click})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aishwaryasatwani/recommenders/examples/00_quick_start/lstur_MIND.ipynb#Y102sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m user_rec_impr_df\n",
      "File \u001b[0;32m~/recommenders/recommender_project/lib/python3.9/site-packages/pandas/core/frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/recommenders/recommender_project/lib/python3.9/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/recommenders/recommender_project/lib/python3.9/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/recommenders/recommender_project/lib/python3.9/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "user_train_ids = []\n",
    "news_rec_train_lists = []\n",
    "news_rec_imp_train_lists = []\n",
    "with open(train_behaviors_file, 'r') as rd:\n",
    "        impr_index = 0\n",
    "        for line in rd:\n",
    "            uid, time, history, impr = line.strip(\"\\n\").split('\\t')[-4:]\n",
    "            impr_news = [i.split(\"-\")[0] for i in impr.split()]\n",
    "            impr_news_click = [i.split(\"-\")[1] for i in impr.split()]\n",
    "            \n",
    "            user_train_ids.append(uid)\n",
    "            news_rec_lists.append(impr_news)\n",
    "            news_rec_imp_train_lists.append(impr_news_click)\n",
    "user_rec_impr_df = pd.DataFrame({'user_id' : user_train_ids, 'news_id': news_rec_lists, 'click' : impr_news_click})\n",
    "user_rec_impr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bypassing download of already-downloaded file MINDsmall_dev.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "# Temporary folder for data we need during execution of this notebook (we'll clean up\n",
    "# at the end, we promise)\n",
    "temp_dir = os.path.join(tempfile.gettempdir(), 'mind')\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# The dataset is split into training and validation set, each with a large and small version.\n",
    "# The format of the four files are the same.\n",
    "# For demonstration purpose, we will use small version validation set only.\n",
    "base_url = 'https://mind201910small.blob.core.windows.net/release'\n",
    "training_small_url = f'{base_url}/MINDsmall_train.zip'\n",
    "validation_small_url = f'{base_url}/MINDsmall_dev.zip'\n",
    "training_large_url = f'{base_url}/MINDlarge_train.zip'\n",
    "validation_large_url = f'{base_url}/MINDlarge_dev.zip'\n",
    "\n",
    "def download_url(url,\n",
    "                 destination_filename=None,\n",
    "                 progress_updater=None,\n",
    "                 force_download=False,\n",
    "                 verbose=True):\n",
    "    \"\"\"\n",
    "    Download a URL to a temporary file\n",
    "    \"\"\"\n",
    "    if not verbose:\n",
    "        progress_updater = None\n",
    "    # This is not intended to guarantee uniqueness, we just know it happens to guarantee\n",
    "    # uniqueness for this application.\n",
    "    if destination_filename is None:\n",
    "        url_as_filename = url.replace('://', '_').replace('/', '_')\n",
    "        destination_filename = \\\n",
    "            os.path.join(temp_dir,url_as_filename)\n",
    "    if (not force_download) and (os.path.isfile(destination_filename)):\n",
    "        if verbose:\n",
    "            print('Bypassing download of already-downloaded file {}'.format(\n",
    "                os.path.basename(url)))\n",
    "        return destination_filename\n",
    "    if verbose:\n",
    "        print('Downloading file {} to {}'.format(os.path.basename(url),\n",
    "                                                 destination_filename),\n",
    "              end='')\n",
    "    urllib.request.urlretrieve(url, destination_filename, progress_updater)\n",
    "    assert (os.path.isfile(destination_filename))\n",
    "    nBytes = os.path.getsize(destination_filename)\n",
    "    if verbose:\n",
    "        print('...done, {} bytes.'.format(nBytes))\n",
    "    return destination_filename\n",
    "\n",
    "zip_path = download_url(validation_small_url, verbose=True)\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_dir)\n",
    "\n",
    "os.listdir(temp_dir)\n",
    "\n",
    "news_path = os.path.join(temp_dir, 'news.tsv')\n",
    "news_df = pd.read_table(news_path,\n",
    "              header=None,\n",
    "              names=[\n",
    "                  'id', 'category', 'subcategory', 'title', 'abstract', 'url',\n",
    "                  'title_entities', 'abstract_entities'\n",
    "              ])\n",
    "news_df.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:39, 5.42MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:16<00:00, 24486.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_similarity(nid_1, nid_2):\n",
    "    if nid_1 not in news_df.index or nid_2 not in news_df.index:\n",
    "        return 0\n",
    "    \n",
    "    cat1 = news_df.loc[nid_1][\"category\"]\n",
    "    cat2 = news_df.loc[nid_2][\"category\"]\n",
    "    if cat1 == cat2:\n",
    "        return 0\n",
    "    return 1-torch.cosine_similarity(glove[cat1].unsqueeze(0), glove[cat2].unsqueeze(0)).item()\n",
    "\n",
    "\n",
    "def diversity_user(user_id, recs, pred_scores, k):\n",
    "    score = 0.0\n",
    "    count = 0.0\n",
    "    combined_data = list(zip(recs, pred_scores))\n",
    "    sorted_data = sorted(combined_data, key=lambda x: x[1])\n",
    "\n",
    "    topk_pairs = sorted_data[:k]\n",
    "    actual_set = user_clicks[user_id]\n",
    "    predicted_set = set(topk_pairs)\n",
    "    intersection_size = len(actual_set.intersection(predicted_set))\n",
    "    union_size = len(actual_set.union(predicted_set))\n",
    "    \n",
    "    accuracy = intersection_size / union_size if union_size > 0 else 1.0\n",
    "    for i in range(len(topk_pairs)):\n",
    "        for j in range(i+1, len(topk_pairs)):\n",
    "            count += 1.0\n",
    "            score += (get_category_similarity(topk_pairs[i][0], topk_pairs[j][0]))\n",
    "    return (score/count, accuracy)\n",
    "        \n",
    "\n",
    "def diversity_eval(df, top_k=5):\n",
    "    diversity_score = 0.0\n",
    "    accuracy_score = 0.0\n",
    "    count = 0.0\n",
    "    for index, row in df.iterrows():\n",
    "        div_score, accuracy = diversity_user(row['user_id'], row['news_id'], row['pred'],top_k)\n",
    "        diversity_score += div_score\n",
    "        accuracy_score += accuracy\n",
    "        \n",
    "        count += 1.0\n",
    "    return (diversity_score/count, accuracy_score/count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_file = pd.read_csv(valid_news_file, sep='\\t', header=None)\n",
    "# news_dict = {}\n",
    "# for i in range(len(news_file[0])):\n",
    "#     news_dict[i] = news_file[0][i]\n",
    "# news_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7538it [00:00, 30719.83it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, 'prediction.txt'), 'w') as f:\n",
    "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "        impr_index += 1\n",
    "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
    "f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7538it [00:00, 37373.05it/s]\n"
     ]
    }
   ],
   "source": [
    "a = \"\"\n",
    "for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "    impr_index += 1\n",
    "    pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "    pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "    a += ' '.join([str(impr_index), pred_rank])+ '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U41827</td>\n",
       "      <td>[N23699, N21291, N1901, N27292, N17443, N18282...</td>\n",
       "      <td>[-0.23009975, -0.29446548, -0.31063515, -0.284...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U61881</td>\n",
       "      <td>[N26916, N4641, N25522, N14893, N19035, N3877,...</td>\n",
       "      <td>[-0.12344916, -0.19023736, -0.11021778, -0.353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U54180</td>\n",
       "      <td>[N13528, N27689, N10879, N11662, N14409, N6849...</td>\n",
       "      <td>[-0.20686844, -0.24127425, -0.4198683, -0.4167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U41164</td>\n",
       "      <td>[N20150, N1807, N26916, N28138, N9576, N19737,...</td>\n",
       "      <td>[0.0710382, -0.3026214, -0.18058312, -0.148491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U8588</td>\n",
       "      <td>[N21325, N5982, N19737, N9576, N20150, N25701,...</td>\n",
       "      <td>[0.045522336, -0.15960245, -0.11037267, -0.096...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>U23841</td>\n",
       "      <td>[N26256, N28117, N2718, N16798, N27689, N6280,...</td>\n",
       "      <td>[-0.40440995, -0.27444282, -0.17943214, -0.174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>U28014</td>\n",
       "      <td>[N26670, N12794, N3390, N17443, N27292, N21852...</td>\n",
       "      <td>[-0.51609087, -0.42063886, -0.37046754, -0.493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>U89684</td>\n",
       "      <td>[N17443, N16798, N24553, N26096, N15927, N2625...</td>\n",
       "      <td>[-0.26791376, -0.15503119, -0.21906719, -0.547...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>U92611</td>\n",
       "      <td>[N14850, N26647, N272, N22751, N21398, N26916,...</td>\n",
       "      <td>[-0.21738777, -0.31038123, -0.06966715, -0.147...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>U329</td>\n",
       "      <td>[N3560, N3390, N13690, N4939, N25735, N5520, N...</td>\n",
       "      <td>[-0.13609181, -0.12234034, -0.20877218, -0.101...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                            news_id  \\\n",
       "0     U41827  [N23699, N21291, N1901, N27292, N17443, N18282...   \n",
       "1     U61881  [N26916, N4641, N25522, N14893, N19035, N3877,...   \n",
       "2     U54180  [N13528, N27689, N10879, N11662, N14409, N6849...   \n",
       "3     U41164  [N20150, N1807, N26916, N28138, N9576, N19737,...   \n",
       "4      U8588  [N21325, N5982, N19737, N9576, N20150, N25701,...   \n",
       "...      ...                                                ...   \n",
       "7533  U23841  [N26256, N28117, N2718, N16798, N27689, N6280,...   \n",
       "7534  U28014  [N26670, N12794, N3390, N17443, N27292, N21852...   \n",
       "7535  U89684  [N17443, N16798, N24553, N26096, N15927, N2625...   \n",
       "7536  U92611  [N14850, N26647, N272, N22751, N21398, N26916,...   \n",
       "7537    U329  [N3560, N3390, N13690, N4939, N25735, N5520, N...   \n",
       "\n",
       "                                                   pred  \n",
       "0     [-0.23009975, -0.29446548, -0.31063515, -0.284...  \n",
       "1     [-0.12344916, -0.19023736, -0.11021778, -0.353...  \n",
       "2     [-0.20686844, -0.24127425, -0.4198683, -0.4167...  \n",
       "3     [0.0710382, -0.3026214, -0.18058312, -0.148491...  \n",
       "4     [0.045522336, -0.15960245, -0.11037267, -0.096...  \n",
       "...                                                 ...  \n",
       "7533  [-0.40440995, -0.27444282, -0.17943214, -0.174...  \n",
       "7534  [-0.51609087, -0.42063886, -0.37046754, -0.493...  \n",
       "7535  [-0.26791376, -0.15503119, -0.21906719, -0.547...  \n",
       "7536  [-0.21738777, -0.31038123, -0.06966715, -0.147...  \n",
       "7537  [-0.13609181, -0.12234034, -0.20877218, -0.101...  \n",
       "\n",
       "[7538 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = []\n",
    "news_rec_lists = []\n",
    "pred_prob = []\n",
    "i = 0\n",
    "with open(valid_behaviors_file, 'r') as rd:\n",
    "        impr_index = 0\n",
    "        for line in rd:\n",
    "            uid, time, history, impr = line.strip(\"\\n\").split('\\t')[-4:]\n",
    "\n",
    "            impr_news = [i.split(\"-\")[0] for i in impr.split()]\n",
    "            user_ids.append(uid)\n",
    "            news_rec_lists.append(impr_news)\n",
    "            pred_prob.append(group_preds[i])\n",
    "            i+=1\n",
    "user_rec_df = pd.DataFrame({'user_id' : user_ids, 'news_id': news_rec_lists, 'pred' : pred_prob})\n",
    "user_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15471620098955108\n"
     ]
    }
   ],
   "source": [
    "print(diversity_eval(user_rec_df, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = user_rec_df[user_rec_df['user_id'] == 'U41827']['pred'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.23009975, -0.29446548, -0.31063515, -0.28458637, -0.52098835,\n",
       "       -0.40606982, -0.3717472 , -0.42147577, -0.4371817 , -0.21698667,\n",
       "       -0.18725532, -0.23469843, -0.4772066 , -0.31384993, -0.33005893,\n",
       "       -0.25722098, -0.05341837, -0.2671283 , -0.24351975, -0.30540362,\n",
       "       -0.38846433, -0.26063126, -0.28985044, -0.16100723, -0.4308247 ,\n",
       "       -0.14284346, -0.08029664, -0.3594852 ], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 12,  8, 24,  7,  5, 20,  6, 27, 14, 13,  2, 19,  1, 22,  3, 17,\n",
       "       21, 15, 18, 11,  0,  9, 10, 23, 25, 26, 16])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 26, 25, 23, 10,  9,  0, 11, 18, 15, 21, 17,  3, 22,  1, 19,  2,\n",
       "       13, 14, 27,  6, 20,  5,  7, 24,  8, 12,  4])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(arr)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7, 15, 17, 13, 28, 23, 21, 24, 26,  6,  5,  8, 27, 18, 19, 10,  1,\n",
       "       12,  9, 16, 22, 11, 14,  4, 25,  3,  2, 20])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argsort(np.argsort(arr)[::-1]) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U41827</td>\n",
       "      <td>[N23699, N21291, N1901, N27292, N17443, N18282...</td>\n",
       "      <td>[0.6221285, 0.48446837, 0.44988602, 0.505597, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U61881</td>\n",
       "      <td>[N26916, N4641, N25522, N14893, N19035, N3877,...</td>\n",
       "      <td>[0.7075086, 0.6030081, 0.72821116, 0.34779397,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U54180</td>\n",
       "      <td>[N13528, N27689, N10879, N11662, N14409, N6849...</td>\n",
       "      <td>[0.50076586, 0.45842782, 0.23865907, 0.2425101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U41164</td>\n",
       "      <td>[N20150, N1807, N26916, N28138, N9576, N19737,...</td>\n",
       "      <td>[1.0, 0.21484806, 0.47128087, 0.5387131, 0.522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U8588</td>\n",
       "      <td>[N21325, N5982, N19737, N9576, N20150, N25701,...</td>\n",
       "      <td>[0.9240295, 0.27624315, 0.43171135, 0.47573537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>U23841</td>\n",
       "      <td>[N26256, N28117, N2718, N16798, N27689, N6280,...</td>\n",
       "      <td>[0.20291752, 0.3977028, 0.54009795, 0.5481512,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>U28014</td>\n",
       "      <td>[N26670, N12794, N3390, N17443, N27292, N21852...</td>\n",
       "      <td>[0.017089143, 0.32717785, 0.49016613, 0.089560...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>U89684</td>\n",
       "      <td>[N17443, N16798, N24553, N26096, N15927, N2625...</td>\n",
       "      <td>[0.3492988, 0.49014106, 0.4102441, 0.0, 0.3336...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>U92611</td>\n",
       "      <td>[N14850, N26647, N272, N22751, N21398, N26916,...</td>\n",
       "      <td>[0.3207426, 0.16066132, 0.5750326, 0.4410269, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>U329</td>\n",
       "      <td>[N3560, N3390, N13690, N4939, N25735, N5520, N...</td>\n",
       "      <td>[0.21653797, 0.257508, 0.0, 0.3181795, 1.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                            news_id  \\\n",
       "0     U41827  [N23699, N21291, N1901, N27292, N17443, N18282...   \n",
       "1     U61881  [N26916, N4641, N25522, N14893, N19035, N3877,...   \n",
       "2     U54180  [N13528, N27689, N10879, N11662, N14409, N6849...   \n",
       "3     U41164  [N20150, N1807, N26916, N28138, N9576, N19737,...   \n",
       "4      U8588  [N21325, N5982, N19737, N9576, N20150, N25701,...   \n",
       "...      ...                                                ...   \n",
       "7533  U23841  [N26256, N28117, N2718, N16798, N27689, N6280,...   \n",
       "7534  U28014  [N26670, N12794, N3390, N17443, N27292, N21852...   \n",
       "7535  U89684  [N17443, N16798, N24553, N26096, N15927, N2625...   \n",
       "7536  U92611  [N14850, N26647, N272, N22751, N21398, N26916,...   \n",
       "7537    U329  [N3560, N3390, N13690, N4939, N25735, N5520, N...   \n",
       "\n",
       "                                                   pred  \n",
       "0     [0.6221285, 0.48446837, 0.44988602, 0.505597, ...  \n",
       "1     [0.7075086, 0.6030081, 0.72821116, 0.34779397,...  \n",
       "2     [0.50076586, 0.45842782, 0.23865907, 0.2425101...  \n",
       "3     [1.0, 0.21484806, 0.47128087, 0.5387131, 0.522...  \n",
       "4     [0.9240295, 0.27624315, 0.43171135, 0.47573537...  \n",
       "...                                                 ...  \n",
       "7533  [0.20291752, 0.3977028, 0.54009795, 0.5481512,...  \n",
       "7534  [0.017089143, 0.32717785, 0.49016613, 0.089560...  \n",
       "7535  [0.3492988, 0.49014106, 0.4102441, 0.0, 0.3336...  \n",
       "7536  [0.3207426, 0.16066132, 0.5750326, 0.4410269, ...  \n",
       "7537  [0.21653797, 0.257508, 0.0, 0.3181795, 1.0, 0....  \n",
       "\n",
       "[7538 rows x 3 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_array(arr):\n",
    "    return (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
    "\n",
    "user_rec_norm_df = user_rec_df\n",
    "user_rec_norm_df['pred'] = user_rec_norm_df['pred'].apply(lambda x: normalize_array(x))\n",
    "user_rec_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nid_1 and nid_2 are news ids (strings)\n",
    "# returns similarity of categories of nid_1 and nid_2 using cosine similarity\n",
    "# if categories don't exist returns 0\n",
    "def get_category_similarity(nid_1, nid_2):\n",
    "    if nid_1 not in news_df.index or nid_2 not in news_df.index:\n",
    "        return 0\n",
    "    \n",
    "    cat1 = news_df.loc[nid_1][\"category\"]\n",
    "    cat2 = news_df.loc[nid_2][\"category\"]\n",
    "    if cat1 == cat2:\n",
    "        return 0\n",
    "    return 1 - torch.cosine_similarity(glove[cat1].unsqueeze(0), glove[cat2].unsqueeze(0)).item()\n",
    "\n",
    "\n",
    "# Calculates mmr score for a given item\n",
    "# item: news id\n",
    "# pred: relevance of item\n",
    "# recs_so_far: list of news ids recommended so far\n",
    "def mmr_item(item, pred, recs_so_far, lamda):\n",
    "    return (lamda * pred) - (1 - lamda) * np.max([1 - get_category_similarity(item, x) for x in recs_so_far])\n",
    "\n",
    "# Calculates list of recommendations\n",
    "# recs is a list of news ids\n",
    "# pred scores is a list of relevance scores, same order as recs\n",
    "# lamda is a weight parameter\n",
    "# k is how many items should be in the recommendation; assume k >= 1\n",
    "def mmr_user(recs, pred_scores, lamda, k):\n",
    "    combined_data = list(zip(recs, pred_scores))\n",
    "    sorted_data = sorted(combined_data, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    list_so_far = [sorted_data[0][0]]\n",
    "    while len(list_so_far) < k:\n",
    "        max_mmr = -2 # mmr can range from -1 to 1\n",
    "        max_mmr_id = ''\n",
    "        for i in range(0, len(recs)): #should be a better way to do this\n",
    "            if recs[i] not in list_so_far:\n",
    "                mmr_score = mmr_item(recs[i], pred_scores[i], list_so_far, lamda)\n",
    "                if mmr_score > max_mmr:\n",
    "                    max_mmr = mmr_score\n",
    "                    max_mmr_id = recs[i]\n",
    "        list_so_far.append(max_mmr_id)\n",
    "    return list_so_far\n",
    "        \n",
    "# Calculates recommendations according to mmr for all users\n",
    "# df is a Pandas dataframe with cols user, news_id, pred where pred[i] is the relevance score for news_id[i]\n",
    "# lamda is a weight parameter\n",
    "# k is how many items should be in the recommendation; assume k >= 1\n",
    "def mmr_all(df, lamda, k):\n",
    "    result_df = {}\n",
    "    for index, row in df.iterrows():\n",
    "        result_df[row['user_id']] = mmr_user(row['news_id'], row['pred'], lamda, k)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[N17774, N1901, N23699, N21291, N13670]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[N21325, N14893, N19829, N25522, N3877]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[N28493, N10879, N20309, N28275, N13690]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[N20150, N28138, N19737, N1807, N26916]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[N20150, N10908, N21325, N5982, N19737]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>7533</td>\n",
       "      <td>[N28275, N28117, N18356, N27689, N697]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>7534</td>\n",
       "      <td>[N9576, N26670, N12794, N3390, N17443]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>7535</td>\n",
       "      <td>[N28275, N20309, N18356, N23094, N22207]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>7536</td>\n",
       "      <td>[N28275, N27137, N272, N18356, N13670]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>7537</td>\n",
       "      <td>[N25735, N3560, N3390, N13690, N4939]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                   news_id\n",
       "0           0   [N17774, N1901, N23699, N21291, N13670]\n",
       "1           1   [N21325, N14893, N19829, N25522, N3877]\n",
       "2           2  [N28493, N10879, N20309, N28275, N13690]\n",
       "3           3   [N20150, N28138, N19737, N1807, N26916]\n",
       "4           4   [N20150, N10908, N21325, N5982, N19737]\n",
       "...       ...                                       ...\n",
       "7533     7533    [N28275, N28117, N18356, N27689, N697]\n",
       "7534     7534    [N9576, N26670, N12794, N3390, N17443]\n",
       "7535     7535  [N28275, N20309, N18356, N23094, N22207]\n",
       "7536     7536    [N28275, N27137, N272, N18356, N13670]\n",
       "7537     7537     [N25735, N3560, N3390, N13690, N4939]\n",
       "\n",
       "[7538 rows x 2 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr_rerank_data = mmr_all(user_rec_norm_df, 0, 5)\n",
    "mmr_rerank_df = pd.DataFrame(list(mmr_rerank_data.items()), columns=['user_id', 'news_id'])\n",
    "\n",
    "mmr_rerank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_user_mmr(recs):\n",
    "    score = 0.0\n",
    "    count = 0.0\n",
    "    for i in range(len(recs)):\n",
    "        for j in range(i+1, len(recs)):\n",
    "            count += 1.0\n",
    "            score += get_category_similarity(recs[i], recs[j])\n",
    "    return score/count\n",
    "\n",
    "def diversity_eval_mmr(df):\n",
    "    diversity_score = 0.0\n",
    "    count = 0.0\n",
    "    for index, row in df.iterrows():\n",
    "        diversity_score += diversity_user_mmr(row['news_id'])\n",
    "        count += 1.0\n",
    "    return diversity_score/count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4740145313376873\n"
     ]
    }
   ],
   "source": [
    "print(diversity_eval_mmr(mmr_rerank_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "for i, row in enumerate(mmr_rerank_df.iterrows()):\n",
    "    actual_set = user_clicks[row['user_id']]\n",
    "    predicted_set = set(row['news_id'])\n",
    "    \n",
    "    intersection_size = len(actual_set.intersection(predicted_set))\n",
    "    union_size = len(actual_set.union(predicted_set))\n",
    "    \n",
    "    accuracy = intersection_size / union_size if union_size > 0 else 1.0\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate mean accuracy\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[N17774, N9181, N21815, N14623, N23699]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[N21325, N19829, N27355, N18356, N27787]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[N28493, N21780, N28275, N21325, N20150]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[N20150, N21325, N28138, N9576, N19737]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[N20150, N21325, N10908, N9576, N19737]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>7533</td>\n",
       "      <td>[N28275, N20150, N21325, N18356, N7067]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>7534</td>\n",
       "      <td>[N9576, N21815, N23829, N26916, N21645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>7535</td>\n",
       "      <td>[N28275, N20150, N21325, N20309, N18356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>7536</td>\n",
       "      <td>[N28275, N24445, N21325, N27137, N18356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>7537</td>\n",
       "      <td>[N25735, N19653, N8620, N5520, N4939]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                   news_id\n",
       "0           0   [N17774, N9181, N21815, N14623, N23699]\n",
       "1           1  [N21325, N19829, N27355, N18356, N27787]\n",
       "2           2  [N28493, N21780, N28275, N21325, N20150]\n",
       "3           3   [N20150, N21325, N28138, N9576, N19737]\n",
       "4           4   [N20150, N21325, N10908, N9576, N19737]\n",
       "...       ...                                       ...\n",
       "7533     7533   [N28275, N20150, N21325, N18356, N7067]\n",
       "7534     7534   [N9576, N21815, N23829, N26916, N21645]\n",
       "7535     7535  [N28275, N20150, N21325, N20309, N18356]\n",
       "7536     7536  [N28275, N24445, N21325, N27137, N18356]\n",
       "7537     7537     [N25735, N19653, N8620, N5520, N4939]\n",
       "\n",
       "[7538 rows x 2 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr_rerank_data_75 = mmr_all(user_rec_norm_df, 0.75, 5)\n",
    "mmr_rerank_df_75 = pd.DataFrame(list(mmr_rerank_data_75.items()), columns=['user_id', 'news_id'])\n",
    "\n",
    "mmr_rerank_df_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28146573441342115\n"
     ]
    }
   ],
   "source": [
    "print(diversity_eval_mmr(mmr_rerank_df_75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "for i, row in enumerate(mmr_rerank_df_75.iterrows()):\n",
    "    actual_set = user_clicks[row['user_id']]\n",
    "    predicted_set = set(row['news_id'])\n",
    "    \n",
    "    intersection_size = len(actual_set.intersection(predicted_set))\n",
    "    union_size = len(actual_set.union(predicted_set))\n",
    "    \n",
    "    accuracy = intersection_size / union_size if union_size > 0 else 1.0\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate mean accuracy\n",
    "mean_accuracy = np.mean(accuracies)\n",
    "print(mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\\[1\\] Mingxiao An, Fangzhao Wu, Chuhan Wu, Kun Zhang, Zheng Liu and Xing Xie: Neural News Recommendation with Long- and Short-term User Representations, ACL 2019<br>\n",
    "\\[2\\] Wu, Fangzhao, et al. \"MIND: A Large-scale Dataset for News Recommendation\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://msnews.github.io/competition.html <br>\n",
    "\\[3\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
