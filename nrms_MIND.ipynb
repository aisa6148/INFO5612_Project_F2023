{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NRMS: Neural News Recommendation with Multi-Head Self-Attention\n",
    "NRMS \\[1\\] is a neural news recommendation approach with multi-head selfattention. The core of NRMS is a news encoder and a user encoder. In the newsencoder, a multi-head self-attentions is used to learn news representations from news titles by modeling the interactions between words. In the user encoder, we learn representations of users from their browsed news and use multihead self-attention to capture the relatedness between the news. Besides, we apply additive\n",
    "attention to learn more informative news and user representations by selecting important words and news.\n",
    "\n",
    "## Properties of NRMS:\n",
    "- NRMS is a content-based neural news recommendation approach.\n",
    "- It uses multi-self attention to learn news representations by modeling the iteractions between words and learn user representations by capturing the relationship between user browsed news.\n",
    "- NRMS uses additive attentions to learn informative news and user representations by selecting important words and news.\n",
    "\n",
    "## Data format:\n",
    "For quicker training and evaluaiton, we sample MINDdemo dataset of 5k users from [MIND small dataset](https://msnews.github.io/). The MINDdemo dataset has the same file format as MINDsmall and MINDlarge. If you want to try experiments on MINDsmall and MINDlarge, please change the dowload source. Select the MIND_type parameter from ['large', 'small', 'demo'] to choose dataset.\n",
    " \n",
    "**MINDdemo_train** is used for training, and **MINDdemo_dev** is used for evaluation. Training data and evaluation data are composed of a news file and a behaviors file. You can find more detailed data description in [MIND repo](https://github.com/msnews/msnews.github.io/blob/master/assets/doc/introduction.md)\n",
    "\n",
    "### news data\n",
    "This file contains news information including newsid, category, subcatgory, news title, news abstarct, news url and entities in news title, entities in news abstarct.\n",
    "One simple example: <br>\n",
    "\n",
    "`N46466\tlifestyle\tlifestyleroyals\tThe Brands Queen Elizabeth, Prince Charles, and Prince Philip Swear By\tShop the notebooks, jackets, and more that the royals can't live without.\thttps://www.msn.com/en-us/lifestyle/lifestyleroyals/the-brands-queen-elizabeth,-prince-charles,-and-prince-philip-swear-by/ss-AAGH0ET?ocid=chopendata\t[{\"Label\": \"Prince Philip, Duke of Edinburgh\", \"Type\": \"P\", \"WikidataId\": \"Q80976\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [48], \"SurfaceForms\": [\"Prince Philip\"]}, {\"Label\": \"Charles, Prince of Wales\", \"Type\": \"P\", \"WikidataId\": \"Q43274\", \"Confidence\": 1.0, \"OccurrenceOffsets\": [28], \"SurfaceForms\": [\"Prince Charles\"]}, {\"Label\": \"Elizabeth II\", \"Type\": \"P\", \"WikidataId\": \"Q9682\", \"Confidence\": 0.97, \"OccurrenceOffsets\": [11], \"SurfaceForms\": [\"Queen Elizabeth\"]}]\t[]`\n",
    "<br>\n",
    "\n",
    "In general, each line in data file represents information of one piece of news: <br>\n",
    "\n",
    "`[News ID] [Category] [Subcategory] [News Title] [News Abstrct] [News Url] [Entities in News Title] [Entities in News Abstract] ...`\n",
    "\n",
    "<br>\n",
    "\n",
    "We generate a word_dict file to transform words in news title to word indexes, and a embedding matrix is initted from pretrained glove embeddings.\n",
    "\n",
    "### behaviors data\n",
    "One simple example: <br>\n",
    "`1\tU82271\t11/11/2019 3:28:58 PM\tN3130 N11621 N12917 N4574 N12140 N9748\tN13390-0 N7180-0 N20785-0 N6937-0 N15776-0 N25810-0 N20820-0 N6885-0 N27294-0 N18835-0 N16945-0 N7410-0 N23967-0 N22679-0 N20532-0 N26651-0 N22078-0 N4098-0 N16473-0 N13841-0 N15660-0 N25787-0 N2315-0 N1615-0 N9087-0 N23880-0 N3600-0 N24479-0 N22882-0 N26308-0 N13594-0 N2220-0 N28356-0 N17083-0 N21415-0 N18671-0 N9440-0 N17759-0 N10861-0 N21830-0 N8064-0 N5675-0 N15037-0 N26154-0 N15368-1 N481-0 N3256-0 N20663-0 N23940-0 N7654-0 N10729-0 N7090-0 N23596-0 N15901-0 N16348-0 N13645-0 N8124-0 N20094-0 N27774-0 N23011-0 N14832-0 N15971-0 N27729-0 N2167-0 N11186-0 N18390-0 N21328-0 N10992-0 N20122-0 N1958-0 N2004-0 N26156-0 N17632-0 N26146-0 N17322-0 N18403-0 N17397-0 N18215-0 N14475-0 N9781-0 N17958-0 N3370-0 N1127-0 N15525-0 N12657-0 N10537-0 N18224-0`\n",
    "<br>\n",
    "\n",
    "In general, each line in data file represents one instance of an impression. The format is like: <br>\n",
    "\n",
    "`[Impression ID] [User ID] [Impression Time] [User Click History] [Impression News]`\n",
    "\n",
    "<br>\n",
    "\n",
    "User Click History is the user historical clicked news before Impression Time. Impression News is the displayed news in an impression, which format is:<br>\n",
    "\n",
    "`[News ID 1]-[label1] ... [News ID n]-[labeln]`\n",
    "\n",
    "<br>\n",
    "Label represents whether the news is clicked by the user. All information of news in User Click History and Impression News can be found in news data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.12 (main, Apr  5 2022, 01:53:17) \n",
      "[Clang 12.0.0 ]\n",
      "Tensorflow version: 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "from recommenders.models.newsrec.models.nrms import NRMSModel\n",
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17.0k/17.0k [00:02<00:00, 7.84kKB/s]\n",
      "100%|██████████| 9.84k/9.84k [00:01<00:00, 6.56kKB/s]\n",
      "100%|██████████| 95.0k/95.0k [00:04<00:00, 19.2kKB/s]\n"
     ]
    }
   ],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "data_path = tmpdir.name\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
    "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\", r'nrms.yaml')\n",
    "\n",
    "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
    "\n",
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, \\\n",
    "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
    "                               os.path.join(data_path, 'utils'), mind_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'support_quick_scoring': True, 'dropout': 0.2, 'attention_hidden_dim': 200, 'head_num': 20, 'head_dim': 20, 'filter_num': 200, 'window_size': 3, 'vert_emb_dim': 100, 'subvert_emb_dim': 100, 'gru_unit': 400, 'type': 'ini', 'user_emb_dim': 50, 'learning_rate': 0.0001, 'optimizer': 'adam', 'epochs': 5, 'batch_size': 32, 'show_step': 10, 'title_size': 30, 'his_size': 50, 'data_format': 'news', 'npratio': 4, 'metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'word_emb_dim': 300, 'model_type': 'nrms', 'loss': 'cross_entropy_loss', 'wordEmb_file': '/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmp0rkqfvdu/utils/embedding.npy', 'wordDict_file': '/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmp0rkqfvdu/utils/word_dict.pkl', 'userDict_file': '/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmp0rkqfvdu/utils/uid2index.pkl'}\n"
     ]
    }
   ],
   "source": [
    "hparams = prepare_hparams(yaml_file, \n",
    "                          wordEmb_file=wordEmb_file,\n",
    "                          wordDict_file=wordDict_file, \n",
    "                          userDict_file=userDict_file,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          show_step=10)\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the NRMS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = MINDIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 14:41:44.862156: W tensorflow/c/c_api.cc:300] Operation '{name:'embedding/embeddings/Assign' id:26 op device:{requested: '', assigned: ''} def:{{{node embedding/embeddings/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](embedding/embeddings, embedding/embeddings/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "/Users/aishwaryasatwani/recommenders/recommender_project/lib/python3.9/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = NRMSModel(hparams, iterator, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmp0rkqfvdu/valid/behaviors.tsv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_behaviors_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/aishwaryasatwani/recommenders/recommender_project/lib/python3.9/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-11-29 13:57:30.780700: W tensorflow/c/c_api.cc:300] Operation '{name:'att_layer2_3/b/Assign' id:2814 op device:{requested: '', assigned: ''} def:{{{node att_layer2_3/b/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](att_layer2_3/b, att_layer2_3/b/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "586it [00:06, 87.21it/s]\n",
      "0it [00:00, ?it/s]2023-11-29 13:57:37.326249: W tensorflow/c/c_api.cc:300] Operation '{name:'att_layer2_3/Sum_1' id:2875 op device:{requested: '', assigned: ''} def:{{{node att_layer2_3/Sum_1}} = Sum[T=DT_FLOAT, Tidx=DT_INT32, _has_manual_control_dependencies=true, keep_dims=false](att_layer2_3/mul, att_layer2_3/Sum_1/reduction_indices)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "236it [01:48,  2.17it/s]\n",
      "7538it [00:00, 17595.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.4792, 'mean_mrr': 0.2059, 'ndcg@5': 0.2045, 'ndcg@10': 0.2701}\n"
     ]
    }
   ],
   "source": [
    "print(model.run_eval(valid_news_file, valid_behaviors_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2023-11-26 15:15:30.074502: W tensorflow/c/c_api.cc:300] Operation '{name:'loss/mul' id:2002 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/activation_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-11-26 15:15:30.183277: W tensorflow/c/c_api.cc:300] Operation '{name:'training/Adam/att_layer2_1/b/v/Assign' id:2807 op device:{requested: '', assigned: ''} def:{{{node training/Adam/att_layer2_1/b/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/att_layer2_1/b/v, training/Adam/att_layer2_1/b/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "step 1080 , total_loss: 1.5141, data_loss: 1.3570: : 1086it [24:09,  1.33s/it]\n",
      "586it [00:06, 96.87it/s]\n",
      "236it [01:48,  2.18it/s]\n",
      "7538it [00:00, 18420.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 1\n",
      "train info: logloss loss:1.5137877671758115\n",
      "eval info: group_auc:0.5785, mean_mrr:0.2436, ndcg@10:0.3298, ndcg@5:0.2578\n",
      "at epoch 1 , train time: 1449.7 eval time: 118.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 1080 , total_loss: 1.4181, data_loss: 1.3567: : 1086it [23:37,  1.31s/it]\n",
      "586it [00:06, 97.22it/s] \n",
      "236it [01:47,  2.20it/s]\n",
      "7538it [00:00, 18310.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 2\n",
      "train info: logloss loss:1.4181900829021883\n",
      "eval info: group_auc:0.6004, mean_mrr:0.2552, ndcg@10:0.346, ndcg@5:0.2711\n",
      "at epoch 2 , train time: 1417.5 eval time: 117.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 1080 , total_loss: 1.3796, data_loss: 1.1591: : 1086it [23:47,  1.31s/it]\n",
      "586it [00:05, 98.63it/s]\n",
      "236it [01:46,  2.22it/s]\n",
      "7538it [00:00, 18000.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 3\n",
      "train info: logloss loss:1.3794216780372746\n",
      "eval info: group_auc:0.6083, mean_mrr:0.2652, ndcg@10:0.3567, ndcg@5:0.2854\n",
      "at epoch 3 , train time: 1427.3 eval time: 116.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 1080 , total_loss: 1.3537, data_loss: 1.1905: : 1086it [23:45,  1.31s/it]\n",
      "586it [00:05, 98.78it/s] \n",
      "236it [01:47,  2.20it/s]\n",
      "7538it [00:00, 17152.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 4\n",
      "train info: logloss loss:1.3537926673340315\n",
      "eval info: group_auc:0.6102, mean_mrr:0.2684, ndcg@10:0.3596, ndcg@5:0.287\n",
      "at epoch 4 , train time: 1425.8 eval time: 117.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step 1080 , total_loss: 1.3297, data_loss: 1.3614: : 1086it [23:44,  1.31s/it]\n",
      "586it [00:05, 99.35it/s]\n",
      "236it [01:46,  2.21it/s]\n",
      "7538it [00:00, 18618.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 5\n",
      "train info: logloss loss:1.3298480067244332\n",
      "eval info: group_auc:0.6136, mean_mrr:0.2698, ndcg@10:0.3617, ndcg@5:0.2901\n",
      "at epoch 5 , train time: 1424.3 eval time: 116.7\n",
      "CPU times: user 13h 17min 40s, sys: 13min 15s, total: 13h 30min 55s\n",
      "Wall time: 2h 8min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<recommenders.models.newsrec.models.nrms.NRMSModel at 0x7faf3d1de9a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "586it [00:06, 96.85it/s]\n",
      "236it [01:48,  2.18it/s]\n",
      "7538it [00:00, 15671.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.4792, 'mean_mrr': 0.2059, 'ndcg@5': 0.2045, 'ndcg@10': 0.2701}\n",
      "CPU times: user 9min 33s, sys: 6.29 s, total: 9min 39s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
    "print(res_syn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/scrapbook.scrap.json+json": {
       "data": {
        "group_auc": 0.4792,
        "mean_mrr": 0.2059,
        "ndcg@10": 0.2701,
        "ndcg@5": 0.2045
       },
       "encoder": "json",
       "name": "res_syn",
       "version": 1
      }
     },
     "metadata": {
      "scrapbook": {
       "data": true,
       "display": false,
       "name": "res_syn"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.glue(\"res_syn\", res_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(data_path, \"model\")\n",
    "os.makedirs(model_path, exist_ok=True)\n",
    "model.model.save_weights(os.path.join(model_path, \"nrms_ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nrms_ckpt.data-00000-of-00001']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_dir = \"/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmp44t_e121/model/\"\n",
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/aishwaryasatwani/recommenders/examples/00_quick_start/nrms_MIND.ipynb Cell 23\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aishwaryasatwani/recommenders/examples/00_quick_start/nrms_MIND.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load the previously saved weights\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aishwaryasatwani/recommenders/examples/00_quick_start/nrms_MIND.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mload_weights(latest)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aishwaryasatwani/recommenders/examples/00_quick_start/nrms_MIND.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Re-evaluate the model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/aishwaryasatwani/recommenders/examples/00_quick_start/nrms_MIND.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m res_syn \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mrun_eval(valid_news_file, valid_behaviors_file)\n",
      "File \u001b[0;32m~/recommenders/recommender_project/lib/python3.9/site-packages/keras/engine/training_v1.py:222\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39msteps_per_run \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    216\u001b[0m         \u001b[39mnot\u001b[39;00m saving_utils\u001b[39m.\u001b[39mis_hdf5_filepath(filepath)\n\u001b[1;32m    217\u001b[0m     ):\n\u001b[1;32m    218\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    219\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLoad weights is not yet supported with TPUStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwith steps_per_run greater than 1.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[0;32m--> 222\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mload_weights(\n\u001b[1;32m    223\u001b[0m     filepath, by_name\u001b[39m=\u001b[39;49mby_name, skip_mismatch\u001b[39m=\u001b[39;49mskip_mismatch\n\u001b[1;32m    224\u001b[0m )\n",
      "File \u001b[0;32m~/recommenders/recommender_project/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/recommenders/recommender_project/lib/python3.9/site-packages/keras/saving/legacy/saving_utils.py:368\u001b[0m, in \u001b[0;36mis_hdf5_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_hdf5_filepath\u001b[39m(filepath):\n\u001b[1;32m    367\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 368\u001b[0m         filepath\u001b[39m.\u001b[39;49mendswith(\u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    369\u001b[0m         \u001b[39mor\u001b[39;00m filepath\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.keras\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    370\u001b[0m         \u001b[39mor\u001b[39;00m filepath\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.hdf5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    371\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "# Load the previously saved weights\n",
    "model.model.load_weights(latest)\n",
    "\n",
    "# Re-evaluate the model\n",
    "res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
    "print(res_syn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Prediction File\n",
    "\n",
    "This code segment is used to generate the prediction.zip file, which is in the same format in [MIND Competition Submission Tutorial](https://competitions.codalab.org/competitions/24122#learn_the_details-submission-guidelines).\n",
    "\n",
    "Please change the `MIND_type` parameter to `large` if you want to submit your prediction to [MIND Competition](https://msnews.github.io/competition.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/aishwaryasatwani/recommenders/recommender_project/lib/python3.9/site-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "2023-12-10 16:53:40.657385: W tensorflow/c/c_api.cc:300] Operation '{name:'self_attention_1/WV/Assign' id:676 op device:{requested: '', assigned: ''} def:{{{node self_attention_1/WV/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](self_attention_1/WV, self_attention_1/WV/Initializer/random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "586it [00:12, 47.16it/s]\n",
      "0it [00:00, ?it/s]2023-12-10 16:53:52.633669: W tensorflow/c/c_api.cc:300] Operation '{name:'att_layer2_1/Sum_1' id:864 op device:{requested: '', assigned: ''} def:{{{node att_layer2_1/Sum_1}} = Sum[T=DT_FLOAT, Tidx=DT_INT32, _has_manual_control_dependencies=true, keep_dims=false](att_layer2_1/mul, att_layer2_1/Sum_1/reduction_indices)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "236it [04:12,  1.07s/it]\n",
      "7538it [00:00, 8428.73it/s]\n"
     ]
    }
   ],
   "source": [
    "group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7538"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(group_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmp44t_e121/valid/news.tsv'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_news_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "news = pd.read_table(valid_news_file)\n",
    "beh = pd.read_table(valid_behaviors_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>U41827</th>\n",
       "      <th>11/15/2019 2:41:03 PM</th>\n",
       "      <th>N15366 N12202 N27489 N19773 N21134 N18191 N6863 N11838 N22940 N11838 N7373 N14672 N20561 N16234 N12038 N25392 N26417 N19248 N7214 N20951 N27993 N21 N16998 N20854 N15119 N12563 N2694 N26376 N6178 N11315 N695 N17348 N16106 N18994 N16620 N19892 N3941 N13178 N17369</th>\n",
       "      <th>N23699-0 N21291-0 N1901-0 N27292-0 N17443-0 N18282-0 N6849-0 N13690-0 N12794-0 N8620-1 N28138-0 N23829-0 N13670-0 N6240-0 N1807-0 N3390-0 N17774-0 N14623-0 N26916-0 N13512-0 N21852-0 N28510-0 N27423-0 N21645-0 N26670-0 N21815-0 N9181-0 N6782-0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>U61881</td>\n",
       "      <td>11/15/2019 10:31:42 AM</td>\n",
       "      <td>N16469 N4202 N4202 N21816 N12992 N24242 N7366 ...</td>\n",
       "      <td>N26916-0 N4641-0 N25522-0 N14893-0 N19035-0 N3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>U54180</td>\n",
       "      <td>11/15/2019 5:36:17 AM</td>\n",
       "      <td>N22427 N16386 N24242 N4385 N14672 N12242 N1852...</td>\n",
       "      <td>N13528-0 N27689-0 N10879-0 N11662-0 N14409-0 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>U41164</td>\n",
       "      <td>11/15/2019 9:13:44 AM</td>\n",
       "      <td>N13065 N5748 N12658 N276 N7395 N16010 N13761 N...</td>\n",
       "      <td>N20150-0 N1807-1 N26916-0 N28138-0 N9576-0 N19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>U8588</td>\n",
       "      <td>11/15/2019 5:39:04 AM</td>\n",
       "      <td>N6629 N4958 N10917 N27079 N828</td>\n",
       "      <td>N21325-0 N5982-0 N19737-1 N9576-0 N20150-0 N25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>U73735</td>\n",
       "      <td>11/15/2019 11:16:40 AM</td>\n",
       "      <td>N8549 N9763 N28048 N5221 N24080 N5358 N11073 N...</td>\n",
       "      <td>N9576-0 N20946-0 N12037-0 N21325-0 N7667-0 N18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>7534</td>\n",
       "      <td>U23841</td>\n",
       "      <td>11/15/2019 9:07:10 AM</td>\n",
       "      <td>N14405 N417 N16730 N23945 N15405 N25316 N13678...</td>\n",
       "      <td>N26256-0 N28117-0 N2718-0 N16798-0 N27689-0 N6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>7535</td>\n",
       "      <td>U28014</td>\n",
       "      <td>11/15/2019 2:06:47 PM</td>\n",
       "      <td>N1053 N26708 N26570 N12924 N24356 N11647 N2759...</td>\n",
       "      <td>N26670-0 N12794-0 N3390-0 N17443-0 N27292-0 N2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>7536</td>\n",
       "      <td>U89684</td>\n",
       "      <td>11/15/2019 9:07:58 AM</td>\n",
       "      <td>N25457 N27206 N23987 N26009 N545 N2573 N22908 ...</td>\n",
       "      <td>N17443-0 N16798-0 N24553-0 N26096-0 N15927-0 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>7537</td>\n",
       "      <td>U92611</td>\n",
       "      <td>11/15/2019 11:52:28 AM</td>\n",
       "      <td>N107 N15735 N11987 N16777 N20030 N26557 N8238 ...</td>\n",
       "      <td>N14850-0 N26647-0 N272-0 N22751-0 N21398-0 N26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>7538</td>\n",
       "      <td>U329</td>\n",
       "      <td>11/15/2019 3:47:32 PM</td>\n",
       "      <td>N21197 N21894 N7360 N5637 N21659 N25315 N1947 ...</td>\n",
       "      <td>N3560-1 N3390-0 N13690-0 N4939-0 N25735-0 N552...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7537 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1  U41827   11/15/2019 2:41:03 PM  \\\n",
       "0        2  U61881  11/15/2019 10:31:42 AM   \n",
       "1        3  U54180   11/15/2019 5:36:17 AM   \n",
       "2        4  U41164   11/15/2019 9:13:44 AM   \n",
       "3        5   U8588   11/15/2019 5:39:04 AM   \n",
       "4        6  U73735  11/15/2019 11:16:40 AM   \n",
       "...    ...     ...                     ...   \n",
       "7532  7534  U23841   11/15/2019 9:07:10 AM   \n",
       "7533  7535  U28014   11/15/2019 2:06:47 PM   \n",
       "7534  7536  U89684   11/15/2019 9:07:58 AM   \n",
       "7535  7537  U92611  11/15/2019 11:52:28 AM   \n",
       "7536  7538    U329   11/15/2019 3:47:32 PM   \n",
       "\n",
       "     N15366 N12202 N27489 N19773 N21134 N18191 N6863 N11838 N22940 N11838 N7373 N14672 N20561 N16234 N12038 N25392 N26417 N19248 N7214 N20951 N27993 N21 N16998 N20854 N15119 N12563 N2694 N26376 N6178 N11315 N695 N17348 N16106 N18994 N16620 N19892 N3941 N13178 N17369  \\\n",
       "0     N16469 N4202 N4202 N21816 N12992 N24242 N7366 ...                                                                                                                                                                                                                      \n",
       "1     N22427 N16386 N24242 N4385 N14672 N12242 N1852...                                                                                                                                                                                                                      \n",
       "2     N13065 N5748 N12658 N276 N7395 N16010 N13761 N...                                                                                                                                                                                                                      \n",
       "3                        N6629 N4958 N10917 N27079 N828                                                                                                                                                                                                                      \n",
       "4     N8549 N9763 N28048 N5221 N24080 N5358 N11073 N...                                                                                                                                                                                                                      \n",
       "...                                                 ...                                                                                                                                                                                                                      \n",
       "7532  N14405 N417 N16730 N23945 N15405 N25316 N13678...                                                                                                                                                                                                                      \n",
       "7533  N1053 N26708 N26570 N12924 N24356 N11647 N2759...                                                                                                                                                                                                                      \n",
       "7534  N25457 N27206 N23987 N26009 N545 N2573 N22908 ...                                                                                                                                                                                                                      \n",
       "7535  N107 N15735 N11987 N16777 N20030 N26557 N8238 ...                                                                                                                                                                                                                      \n",
       "7536  N21197 N21894 N7360 N5637 N21659 N25315 N1947 ...                                                                                                                                                                                                                      \n",
       "\n",
       "     N23699-0 N21291-0 N1901-0 N27292-0 N17443-0 N18282-0 N6849-0 N13690-0 N12794-0 N8620-1 N28138-0 N23829-0 N13670-0 N6240-0 N1807-0 N3390-0 N17774-0 N14623-0 N26916-0 N13512-0 N21852-0 N28510-0 N27423-0 N21645-0 N26670-0 N21815-0 N9181-0 N6782-0  \n",
       "0     N26916-0 N4641-0 N25522-0 N14893-0 N19035-0 N3...                                                                                                                                                                                                   \n",
       "1     N13528-0 N27689-0 N10879-0 N11662-0 N14409-0 N...                                                                                                                                                                                                   \n",
       "2     N20150-0 N1807-1 N26916-0 N28138-0 N9576-0 N19...                                                                                                                                                                                                   \n",
       "3     N21325-0 N5982-0 N19737-1 N9576-0 N20150-0 N25...                                                                                                                                                                                                   \n",
       "4     N9576-0 N20946-0 N12037-0 N21325-0 N7667-0 N18...                                                                                                                                                                                                   \n",
       "...                                                 ...                                                                                                                                                                                                   \n",
       "7532  N26256-0 N28117-0 N2718-0 N16798-0 N27689-0 N6...                                                                                                                                                                                                   \n",
       "7533  N26670-0 N12794-0 N3390-0 N17443-0 N27292-0 N2...                                                                                                                                                                                                   \n",
       "7534  N17443-0 N16798-0 N24553-0 N26096-0 N15927-0 N...                                                                                                                                                                                                   \n",
       "7535  N14850-0 N26647-0 N272-0 N22751-0 N21398-0 N26...                                                                                                                                                                                                   \n",
       "7536  N3560-1 N3390-0 N13690-0 N4939-0 N25735-0 N552...                                                                                                                                                                                                   \n",
       "\n",
       "[7537 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7538it [00:00, 60006.42it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, 'prediction.txt'), 'w') as f: \n",
    "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "        impr_index += 1\n",
    "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15,\n",
       " 7,\n",
       " 11,\n",
       " 5,\n",
       " 21,\n",
       " 24,\n",
       " 17,\n",
       " 16,\n",
       " 26,\n",
       " 13,\n",
       " 18,\n",
       " 22,\n",
       " 12,\n",
       " 2,\n",
       " 23,\n",
       " 28,\n",
       " 8,\n",
       " 25,\n",
       " 19,\n",
       " 10,\n",
       " 4,\n",
       " 20,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 14,\n",
       " 3,\n",
       " 27]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argsort(np.argsort(group_preds[0])[::-1]) + 1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/var/folders/sv/970s472x5tz75kxxbpmggty40000gn/T/tmpyjb6wdcd'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
    "f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7538it [00:00, 57803.29it/s]\n"
     ]
    }
   ],
   "source": [
    "a = \"\"\n",
    "for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "    impr_index += 1\n",
    "    pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "    pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "    a += ' '.join([str(impr_index), pred_rank])+ '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bypassing download of already-downloaded file MINDsmall_dev.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "# Temporary folder for data we need during execution of this notebook (we'll clean up\n",
    "# at the end, we promise)\n",
    "temp_dir = os.path.join(tempfile.gettempdir(), 'mind')\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "# The dataset is split into training and validation set, each with a large and small version.\n",
    "# The format of the four files are the same.\n",
    "# For demonstration purpose, we will use small version validation set only.\n",
    "base_url = 'https://mind201910small.blob.core.windows.net/release'\n",
    "training_small_url = f'{base_url}/MINDsmall_train.zip'\n",
    "validation_small_url = f'{base_url}/MINDsmall_dev.zip'\n",
    "training_large_url = f'{base_url}/MINDlarge_train.zip'\n",
    "validation_large_url = f'{base_url}/MINDlarge_dev.zip'\n",
    "\n",
    "def download_url(url,\n",
    "                 destination_filename=None,\n",
    "                 progress_updater=None,\n",
    "                 force_download=False,\n",
    "                 verbose=True):\n",
    "    \"\"\"\n",
    "    Download a URL to a temporary file\n",
    "    \"\"\"\n",
    "    if not verbose:\n",
    "        progress_updater = None\n",
    "    # This is not intended to guarantee uniqueness, we just know it happens to guarantee\n",
    "    # uniqueness for this application.\n",
    "    if destination_filename is None:\n",
    "        url_as_filename = url.replace('://', '_').replace('/', '_')\n",
    "        destination_filename = \\\n",
    "            os.path.join(temp_dir,url_as_filename)\n",
    "    if (not force_download) and (os.path.isfile(destination_filename)):\n",
    "        if verbose:\n",
    "            print('Bypassing download of already-downloaded file {}'.format(\n",
    "                os.path.basename(url)))\n",
    "        return destination_filename\n",
    "    if verbose:\n",
    "        print('Downloading file {} to {}'.format(os.path.basename(url),\n",
    "                                                 destination_filename),\n",
    "              end='')\n",
    "    urllib.request.urlretrieve(url, destination_filename, progress_updater)\n",
    "    assert (os.path.isfile(destination_filename))\n",
    "    nBytes = os.path.getsize(destination_filename)\n",
    "    if verbose:\n",
    "        print('...done, {} bytes.'.format(nBytes))\n",
    "    return destination_filename\n",
    "\n",
    "zip_path = download_url(validation_small_url, verbose=True)\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_dir)\n",
    "\n",
    "os.listdir(temp_dir)\n",
    "\n",
    "news_path = os.path.join(temp_dir, 'news.tsv')\n",
    "news_df = pd.read_table(news_path,\n",
    "              header=None,\n",
    "              names=[\n",
    "                  'id', 'category', 'subcategory', 'title', 'abstract', 'url',\n",
    "                  'title_entities', 'abstract_entities'\n",
    "              ])\n",
    "news_df.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_similarity(nid_1, nid_2):\n",
    "    if nid_1 not in news_df.index or nid_2 not in news_df.index:\n",
    "        return 0\n",
    "    \n",
    "    cat1 = news_df.loc[nid_1][\"category\"]\n",
    "    cat2 = news_df.loc[nid_2][\"category\"]\n",
    "    \n",
    "    return 1-torch.cosine_similarity(glove[cat1].unsqueeze(0), glove[cat2].unsqueeze(0)).item()\n",
    "\n",
    "\n",
    "def diversity_user(recs, pred_scores, k):\n",
    "    score = 0.0\n",
    "    count = 0.0\n",
    "    combined_data = list(zip(recs, pred_scores))\n",
    "    sorted_data = sorted(combined_data, key=lambda x: x[1])\n",
    "\n",
    "    topk_pairs = sorted_data[:k]\n",
    "    for i in range(len(topk_pairs)):\n",
    "        for j in range(i+1, len(topk_pairs)):\n",
    "            count += 1.0\n",
    "            score += (1-get_category_similarity(topk_pairs[i][0], topk_pairs[j][0]))\n",
    "    return score/count\n",
    "        \n",
    "\n",
    "def diversity_eval(df, top_k=5):\n",
    "    diversity_score = 0.0\n",
    "    count = 0.0\n",
    "    for index, row in df.iterrows():\n",
    "        diversity_score += diversity_user(row['news_id'], row['pred'],top_k)\n",
    "        count += 1.0\n",
    "    return diversity_score/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U41827</td>\n",
       "      <td>[N23699, N21291, N1901, N27292, N17443, N18282...</td>\n",
       "      <td>[-0.016029868, 0.028213965, 0.00374203, 0.0324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U61881</td>\n",
       "      <td>[N26916, N4641, N25522, N14893, N19035, N3877,...</td>\n",
       "      <td>[-0.08410066, -0.07030145, -0.14174062, -0.028...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U54180</td>\n",
       "      <td>[N13528, N27689, N10879, N11662, N14409, N6849...</td>\n",
       "      <td>[-0.027243517, -0.02682752, 0.014758418, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U41164</td>\n",
       "      <td>[N20150, N1807, N26916, N28138, N9576, N19737,...</td>\n",
       "      <td>[-0.07029299, -0.06975028, -0.051979825, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U8588</td>\n",
       "      <td>[N21325, N5982, N19737, N9576, N20150, N25701,...</td>\n",
       "      <td>[-0.009216756, -0.0034534195, 0.00040009664, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>U23841</td>\n",
       "      <td>[N26256, N28117, N2718, N16798, N27689, N6280,...</td>\n",
       "      <td>[-0.04028006, -0.06562622, 0.016713316, -0.003...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>U28014</td>\n",
       "      <td>[N26670, N12794, N3390, N17443, N27292, N21852...</td>\n",
       "      <td>[-0.0031647116, -0.019335303, -0.042360865, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>U89684</td>\n",
       "      <td>[N17443, N16798, N24553, N26096, N15927, N2625...</td>\n",
       "      <td>[-0.026421571, -0.008083752, -0.014075289, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>U92611</td>\n",
       "      <td>[N14850, N26647, N272, N22751, N21398, N26916,...</td>\n",
       "      <td>[-0.039575763, -0.094993755, -0.020876817, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>U329</td>\n",
       "      <td>[N3560, N3390, N13690, N4939, N25735, N5520, N...</td>\n",
       "      <td>[0.0155255385, -0.23416096, -0.061219566, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                            news_id  \\\n",
       "0     U41827  [N23699, N21291, N1901, N27292, N17443, N18282...   \n",
       "1     U61881  [N26916, N4641, N25522, N14893, N19035, N3877,...   \n",
       "2     U54180  [N13528, N27689, N10879, N11662, N14409, N6849...   \n",
       "3     U41164  [N20150, N1807, N26916, N28138, N9576, N19737,...   \n",
       "4      U8588  [N21325, N5982, N19737, N9576, N20150, N25701,...   \n",
       "...      ...                                                ...   \n",
       "7533  U23841  [N26256, N28117, N2718, N16798, N27689, N6280,...   \n",
       "7534  U28014  [N26670, N12794, N3390, N17443, N27292, N21852...   \n",
       "7535  U89684  [N17443, N16798, N24553, N26096, N15927, N2625...   \n",
       "7536  U92611  [N14850, N26647, N272, N22751, N21398, N26916,...   \n",
       "7537    U329  [N3560, N3390, N13690, N4939, N25735, N5520, N...   \n",
       "\n",
       "                                                   pred  \n",
       "0     [-0.016029868, 0.028213965, 0.00374203, 0.0324...  \n",
       "1     [-0.08410066, -0.07030145, -0.14174062, -0.028...  \n",
       "2     [-0.027243517, -0.02682752, 0.014758418, -0.04...  \n",
       "3     [-0.07029299, -0.06975028, -0.051979825, -0.05...  \n",
       "4     [-0.009216756, -0.0034534195, 0.00040009664, -...  \n",
       "...                                                 ...  \n",
       "7533  [-0.04028006, -0.06562622, 0.016713316, -0.003...  \n",
       "7534  [-0.0031647116, -0.019335303, -0.042360865, -0...  \n",
       "7535  [-0.026421571, -0.008083752, -0.014075289, -0....  \n",
       "7536  [-0.039575763, -0.094993755, -0.020876817, -0....  \n",
       "7537  [0.0155255385, -0.23416096, -0.061219566, -0.0...  \n",
       "\n",
       "[7538 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = []\n",
    "news_rec_lists = []\n",
    "pred_prob = []\n",
    "i = 0\n",
    "with open(valid_behaviors_file, 'r') as rd:\n",
    "        impr_index = 0\n",
    "        for line in rd:\n",
    "            uid, time, history, impr = line.strip(\"\\n\").split('\\t')[-4:]\n",
    "\n",
    "            impr_news = [i.split(\"-\")[0] for i in impr.split()]\n",
    "            user_ids.append(uid)\n",
    "            news_rec_lists.append(impr_news)\n",
    "            pred_prob.append(group_preds[i])\n",
    "            i+=1\n",
    "user_rec_df = pd.DataFrame({'user_id' : user_ids, 'news_id': news_rec_lists, 'pred' : pred_prob})\n",
    "user_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8884769746792819\n"
     ]
    }
   ],
   "source": [
    "print(diversity_eval(user_rec_df, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U41827</td>\n",
       "      <td>[N23699, N21291, N1901, N27292, N17443, N18282...</td>\n",
       "      <td>[0.62596655, 0.81248397, 0.7093183, 0.8301947,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U61881</td>\n",
       "      <td>[N26916, N4641, N25522, N14893, N19035, N3877,...</td>\n",
       "      <td>[0.39407927, 0.4602602, 0.11763841, 0.66133386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U54180</td>\n",
       "      <td>[N13528, N27689, N10879, N11662, N14409, N6849...</td>\n",
       "      <td>[0.564781, 0.5672953, 0.8186482, 0.46154946, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U41164</td>\n",
       "      <td>[N20150, N1807, N26916, N28138, N9576, N19737,...</td>\n",
       "      <td>[0.15490122, 0.1590584, 0.29518163, 0.23938416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U8588</td>\n",
       "      <td>[N21325, N5982, N19737, N9576, N20150, N25701,...</td>\n",
       "      <td>[0.50092185, 0.8000171, 1.0, 0.6226852, 0.7715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>U23841</td>\n",
       "      <td>[N26256, N28117, N2718, N16798, N27689, N6280,...</td>\n",
       "      <td>[0.456568, 0.29370573, 0.82278013, 0.6918397, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>U28014</td>\n",
       "      <td>[N26670, N12794, N3390, N17443, N27292, N21852...</td>\n",
       "      <td>[0.9205003, 0.54074275, 0.0, 0.70027363, 0.941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>U89684</td>\n",
       "      <td>[N17443, N16798, N24553, N26096, N15927, N2625...</td>\n",
       "      <td>[0.30298424, 0.67076075, 0.5505967, 0.5666304,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>U92611</td>\n",
       "      <td>[N14850, N26647, N272, N22751, N21398, N26916,...</td>\n",
       "      <td>[0.38258368, 0.15424332, 0.45962948, 0.3384243...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>U329</td>\n",
       "      <td>[N3560, N3390, N13690, N4939, N25735, N5520, N...</td>\n",
       "      <td>[0.8995898, 0.0, 0.6230866, 0.6076212, 0.37589...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                            news_id  \\\n",
       "0     U41827  [N23699, N21291, N1901, N27292, N17443, N18282...   \n",
       "1     U61881  [N26916, N4641, N25522, N14893, N19035, N3877,...   \n",
       "2     U54180  [N13528, N27689, N10879, N11662, N14409, N6849...   \n",
       "3     U41164  [N20150, N1807, N26916, N28138, N9576, N19737,...   \n",
       "4      U8588  [N21325, N5982, N19737, N9576, N20150, N25701,...   \n",
       "...      ...                                                ...   \n",
       "7533  U23841  [N26256, N28117, N2718, N16798, N27689, N6280,...   \n",
       "7534  U28014  [N26670, N12794, N3390, N17443, N27292, N21852...   \n",
       "7535  U89684  [N17443, N16798, N24553, N26096, N15927, N2625...   \n",
       "7536  U92611  [N14850, N26647, N272, N22751, N21398, N26916,...   \n",
       "7537    U329  [N3560, N3390, N13690, N4939, N25735, N5520, N...   \n",
       "\n",
       "                                                   pred  \n",
       "0     [0.62596655, 0.81248397, 0.7093183, 0.8301947,...  \n",
       "1     [0.39407927, 0.4602602, 0.11763841, 0.66133386...  \n",
       "2     [0.564781, 0.5672953, 0.8186482, 0.46154946, 0...  \n",
       "3     [0.15490122, 0.1590584, 0.29518163, 0.23938416...  \n",
       "4     [0.50092185, 0.8000171, 1.0, 0.6226852, 0.7715...  \n",
       "...                                                 ...  \n",
       "7533  [0.456568, 0.29370573, 0.82278013, 0.6918397, ...  \n",
       "7534  [0.9205003, 0.54074275, 0.0, 0.70027363, 0.941...  \n",
       "7535  [0.30298424, 0.67076075, 0.5505967, 0.5666304,...  \n",
       "7536  [0.38258368, 0.15424332, 0.45962948, 0.3384243...  \n",
       "7537  [0.8995898, 0.0, 0.6230866, 0.6076212, 0.37589...  \n",
       "\n",
       "[7538 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_array(arr):\n",
    "    return (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
    "\n",
    "user_rec_norm_df = user_rec_df\n",
    "user_rec_norm_df['pred'] = user_rec_norm_df['pred'].apply(lambda x: normalize_array(x))\n",
    "user_rec_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nid_1 and nid_2 are news ids (strings)\n",
    "# returns similarity of categories of nid_1 and nid_2 using cosine similarity\n",
    "# if categories don't exist returns 0\n",
    "def get_category_similarity(nid_1, nid_2):\n",
    "    if nid_1 not in news_df.index or nid_2 not in news_df.index:\n",
    "        return 0\n",
    "    \n",
    "    cat1 = news_df.loc[nid_1][\"category\"]\n",
    "    cat2 = news_df.loc[nid_2][\"category\"]\n",
    "    \n",
    "    return 1 - torch.cosine_similarity(glove[cat1].unsqueeze(0), glove[cat2].unsqueeze(0)).item()\n",
    "\n",
    "\n",
    "# Calculates mmr score for a given item\n",
    "# item: news id\n",
    "# pred: relevance of item\n",
    "# recs_so_far: list of news ids recommended so far\n",
    "def mmr_item(item, pred, recs_so_far, lamda):\n",
    "    return (lamda * pred) - (1 - lamda) * np.max([1 - get_category_similarity(item, x) for x in recs_so_far])\n",
    "\n",
    "# Calculates list of recommendations\n",
    "# recs is a list of news ids\n",
    "# pred scores is a list of relevance scores, same order as recs\n",
    "# lamda is a weight parameter\n",
    "# k is how many items should be in the recommendation; assume k >= 1\n",
    "def mmr_user(recs, pred_scores, lamda, k):\n",
    "    list_so_far = [recs[0]]\n",
    "    while len(list_so_far) < k:\n",
    "        max_mmr = -2 # mmr can range from -1 to 1\n",
    "        max_mmr_id = ''\n",
    "        for i in range(0, len(recs)): #should be a better way to do this\n",
    "            if recs[i] not in list_so_far:\n",
    "                mmr_score = mmr_item(recs[i], pred_scores[i], list_so_far, lamda)\n",
    "                if mmr_score > max_mmr:\n",
    "                    max_mmr = mmr_score\n",
    "                    max_mmr_id = recs[i]\n",
    "        list_so_far.append(max_mmr_id)\n",
    "    return list_so_far\n",
    "        \n",
    "# Calculates recommendations according to mmr for all users\n",
    "# df is a Pandas dataframe with cols user, news_id, pred where pred[i] is the relevance score for news_id[i]\n",
    "# lamda is a weight parameter\n",
    "# k is how many items should be in the recommendation; assume k >= 1\n",
    "def mmr_all(df, lamda, k):\n",
    "    result_df = {}\n",
    "    for index, row in df.iterrows():\n",
    "        result_df[index] = mmr_user(row['news_id'], row['pred'], lamda, k)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>news_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[N23699, N13670, N1901, N28138, N27292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[N26916, N4641, N25522, N14893, N19035]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[N13528, N10879, N10908, N13690, N20309]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[N20150, N28138, N19737, N1807, N26916]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[N21325, N10908, N20150, N25701, N13530]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>7533</td>\n",
       "      <td>[N26256, N28117, N2718, N16798, N27689]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>7534</td>\n",
       "      <td>[N26670, N12794, N3390, N17443, N27292]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>7535</td>\n",
       "      <td>[N17443, N23094, N25522, N20309, N18356]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>7536</td>\n",
       "      <td>[N14850, N27137, N272, N22130, N13670]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>7537</td>\n",
       "      <td>[N3560, N5520, N13690, N4939, N8620]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7538 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                   news_id\n",
       "0           0   [N23699, N13670, N1901, N28138, N27292]\n",
       "1           1   [N26916, N4641, N25522, N14893, N19035]\n",
       "2           2  [N13528, N10879, N10908, N13690, N20309]\n",
       "3           3   [N20150, N28138, N19737, N1807, N26916]\n",
       "4           4  [N21325, N10908, N20150, N25701, N13530]\n",
       "...       ...                                       ...\n",
       "7533     7533   [N26256, N28117, N2718, N16798, N27689]\n",
       "7534     7534   [N26670, N12794, N3390, N17443, N27292]\n",
       "7535     7535  [N17443, N23094, N25522, N20309, N18356]\n",
       "7536     7536    [N14850, N27137, N272, N22130, N13670]\n",
       "7537     7537      [N3560, N5520, N13690, N4939, N8620]\n",
       "\n",
       "[7538 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmr_rerank_data = mmr_all(user_rec_norm_df, 0, 5)\n",
    "mmr_rerank_df = pd.DataFrame(list(mmr_rerank_data.items()), columns=['user_id', 'news_id'])\n",
    "\n",
    "mmr_rerank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_user_mmr(recs):\n",
    "    score = 0.0\n",
    "    count = 0.0\n",
    "    for i in range(len(recs)):\n",
    "        for j in range(i+1, len(recs)):\n",
    "            count += 1.0\n",
    "            score += 1-get_category_similarity(recs[i], recs[j])\n",
    "    return score/count\n",
    "\n",
    "def diversity_eval_mmr(df):\n",
    "    diversity_score = 0.0\n",
    "    count = 0.0\n",
    "    for index, row in df.iterrows():\n",
    "        diversity_score += diversity_user_mmr(row['news_id'])\n",
    "        count += 1.0\n",
    "    return diversity_score/count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6016681731163404\n"
     ]
    }
   ],
   "source": [
    "print(diversity_eval_mmr(mmr_rerank_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\\[1\\] Wu et al. \"Neural News Recommendation with Multi-Head Self-Attention.\" in Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<br>\n",
    "\\[2\\] Wu, Fangzhao, et al. \"MIND: A Large-scale Dataset for News Recommendation\" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. https://msnews.github.io/competition.html <br>\n",
    "\\[3\\] GloVe: Global Vectors for Word Representation. https://nlp.stanford.edu/projects/glove/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('tf2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
