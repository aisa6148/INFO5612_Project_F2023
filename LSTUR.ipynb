{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTUR: Neural News Recommendation with Long- and Short-term User Representations\n",
    "LSTUR \\[1\\] is a news recommendation approach capturing users' both long-term preferences and short-term interests. The core of LSTUR is a news encoder and a user encoder.  In the news encoder, we learn representations of news from their titles. In user encoder, we propose to learn long-term\n",
    "user representations from the embeddings of their IDs. In addition, we propose to learn short-term user representations from their recently browsed news via GRU network. Besides, we propose two methods to combine\n",
    "long-term and short-term user representations. The first one is using the long-term user representation to initialize the hidden state of the GRU network in short-term user representation. The second one is concatenating both\n",
    "long- and short-term user representations as a unified user vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]\n",
      "Tensorflow version: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "import scrapbook as sb\n",
    "from tempfile import TemporaryDirectory\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.models.deeprec.deeprec_utils import download_deeprec_resources \n",
    "from recommenders.models.newsrec.newsrec_utils import prepare_hparams\n",
    "from recommenders.models.newsrec.models.lstur import LSTURModel\n",
    "from recommenders.models.newsrec.io.mind_iterator import MINDIterator\n",
    "from recommenders.models.newsrec.newsrec_utils import get_mind_data_set\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import MMR\n",
    "import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17.0k/17.0k [00:01<00:00, 9.21kKB/s]\n",
      "100%|██████████| 9.84k/9.84k [00:01<00:00, 5.85kKB/s]\n",
      "100%|██████████| 95.0k/95.0k [00:27<00:00, 3.47kKB/s]\n"
     ]
    }
   ],
   "source": [
    "tmpdir = TemporaryDirectory()\n",
    "data_path = tmpdir.name\n",
    "# Options: demo, small, large\n",
    "MIND_type = 'demo'\n",
    "\n",
    "train_news_file = os.path.join(data_path, 'train', r'news.tsv')\n",
    "train_behaviors_file = os.path.join(data_path, 'train', r'behaviors.tsv')\n",
    "valid_news_file = os.path.join(data_path, 'valid', r'news.tsv')\n",
    "valid_behaviors_file = os.path.join(data_path, 'valid', r'behaviors.tsv')\n",
    "wordEmb_file = os.path.join(data_path, \"utils\", \"embedding.npy\")\n",
    "userDict_file = os.path.join(data_path, \"utils\", \"uid2index.pkl\")\n",
    "wordDict_file = os.path.join(data_path, \"utils\", \"word_dict.pkl\")\n",
    "yaml_file = os.path.join(data_path, \"utils\", r'lstur.yaml')\n",
    "\n",
    "mind_url, mind_train_dataset, mind_dev_dataset, mind_utils = get_mind_data_set(MIND_type)\n",
    "\n",
    "if not os.path.exists(train_news_file):\n",
    "    download_deeprec_resources(mind_url, os.path.join(data_path, 'train'), mind_train_dataset)\n",
    "    \n",
    "if not os.path.exists(valid_news_file):\n",
    "    download_deeprec_resources(mind_url, \\\n",
    "                               os.path.join(data_path, 'valid'), mind_dev_dataset)\n",
    "if not os.path.exists(yaml_file):\n",
    "    download_deeprec_resources(r'https://recodatasets.z20.web.core.windows.net/newsrec/', \\\n",
    "                               os.path.join(data_path, 'utils'), mind_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "seed = 40\n",
    "batch_size = 32\n",
    "\n",
    "def train_model():\n",
    "    hparams = prepare_hparams(yaml_file, \n",
    "                          wordEmb_file=wordEmb_file,\n",
    "                          wordDict_file=wordDict_file, \n",
    "                          userDict_file=userDict_file,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs)\n",
    "    print(hparams)\n",
    "    model = LSTURModel(hparams, MINDIterator, seed=seed)\n",
    "    print(model.run_eval(valid_news_file, valid_behaviors_file))\n",
    "    model.fit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HParams object with values {'support_quick_scoring': True, 'dropout': 0.2, 'attention_hidden_dim': 200, 'head_num': 4, 'head_dim': 100, 'filter_num': 400, 'window_size': 3, 'vert_emb_dim': 100, 'subvert_emb_dim': 100, 'gru_unit': 400, 'type': 'ini', 'user_emb_dim': 50, 'learning_rate': 0.0001, 'optimizer': 'adam', 'epochs': 5, 'batch_size': 32, 'show_step': 100000, 'title_size': 30, 'his_size': 50, 'data_format': 'news', 'npratio': 4, 'metrics': ['group_auc', 'mean_mrr', 'ndcg@5;10'], 'word_emb_dim': 300, 'cnn_activation': 'relu', 'model_type': 'lstur', 'loss': 'cross_entropy_loss', 'wordEmb_file': 'C:\\\\Users\\\\Eliza\\\\AppData\\\\Local\\\\Temp\\\\tmpjylb0wsv\\\\utils\\\\embedding.npy', 'wordDict_file': 'C:\\\\Users\\\\Eliza\\\\AppData\\\\Local\\\\Temp\\\\tmpjylb0wsv\\\\utils\\\\word_dict.pkl', 'userDict_file': 'C:\\\\Users\\\\Eliza\\\\AppData\\\\Local\\\\Temp\\\\tmpjylb0wsv\\\\utils\\\\uid2index.pkl'}\n",
      "Tensor(\"conv1d/Relu:0\", shape=(None, 30, 400), dtype=float32)\n",
      "Tensor(\"att_layer2/Sum_1:0\", shape=(None, 400), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Eliza\\anaconda3\\envs\\info_5612_project\\lib\\site-packages\\keras\\src\\optimizers\\legacy\\adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "0it [00:00, ?it/s]c:\\Users\\Eliza\\anaconda3\\envs\\info_5612_project\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "586it [00:08, 72.63it/s] \n",
      "236it [02:15,  1.74it/s]\n",
      "7538it [00:01, 4185.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'group_auc': 0.5201, 'mean_mrr': 0.2214, 'ndcg@5': 0.2292, 'ndcg@10': 0.2912}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1086it [1:04:24,  3.56s/it]\n",
      "586it [00:13, 44.47it/s]\n",
      "236it [03:58,  1.01s/it]\n",
      "7538it [00:03, 2394.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at epoch 1\n",
      "train info: logloss loss:1.4884230886375047\n",
      "eval info: group_auc:0.5935, mean_mrr:0.2566, ndcg@10:0.3459, ndcg@5:0.2806\n",
      "at epoch 1 , train time: 3864.1 eval time: 274.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "55it [04:39,  5.08s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Eliza\\OneDrive\\Github\\INFO5612_Project_F2023\\LSTUR.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Eliza/OneDrive/Github/INFO5612_Project_F2023/LSTUR.ipynb#Y132sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m train_model()\n",
      "\u001b[1;32mc:\\Users\\Eliza\\OneDrive\\Github\\INFO5612_Project_F2023\\LSTUR.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eliza/OneDrive/Github/INFO5612_Project_F2023/LSTUR.ipynb#Y132sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m model \u001b[39m=\u001b[39m LSTURModel(hparams, MINDIterator, seed\u001b[39m=\u001b[39mseed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eliza/OneDrive/Github/INFO5612_Project_F2023/LSTUR.ipynb#Y132sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mrun_eval(valid_news_file, valid_behaviors_file))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Eliza/OneDrive/Github/INFO5612_Project_F2023/LSTUR.ipynb#Y132sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Eliza/OneDrive/Github/INFO5612_Project_F2023/LSTUR.ipynb#Y132sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\Eliza\\anaconda3\\envs\\info_5612_project\\lib\\site-packages\\recommenders\\models\\newsrec\\models\\base_model.py:216\u001b[0m, in \u001b[0;36mBaseModel.fit\u001b[1;34m(self, train_news_file, train_behaviors_file, valid_news_file, valid_behaviors_file, test_news_file, test_behaviors_file)\u001b[0m\n\u001b[0;32m    208\u001b[0m tqdm_util \u001b[39m=\u001b[39m tqdm(\n\u001b[0;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_iterator\u001b[39m.\u001b[39mload_data_from_file(\n\u001b[0;32m    210\u001b[0m         train_news_file, train_behaviors_file\n\u001b[0;32m    211\u001b[0m     )\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    214\u001b[0m \u001b[39mfor\u001b[39;00m batch_data_input \u001b[39min\u001b[39;00m tqdm_util:\n\u001b[1;32m--> 216\u001b[0m     step_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(batch_data_input)\n\u001b[0;32m    217\u001b[0m     step_data_loss \u001b[39m=\u001b[39m step_result\n\u001b[0;32m    219\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m step_data_loss\n",
      "File \u001b[1;32mc:\\Users\\Eliza\\anaconda3\\envs\\info_5612_project\\lib\\site-packages\\recommenders\\models\\newsrec\\models\\base_model.py:161\u001b[0m, in \u001b[0;36mBaseModel.train\u001b[1;34m(self, train_batch_data)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Go through the optimization step once with training data in feed_dict.\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[0;32m    153\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[39m    list: A list of values, including update operation, total loss, data loss, and merged summary.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m train_input, train_label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_input_label_from_iter(train_batch_data)\n\u001b[1;32m--> 161\u001b[0m rslt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtrain_on_batch(train_input, train_label)\n\u001b[0;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m rslt\n",
      "File \u001b[1;32mc:\\Users\\Eliza\\anaconda3\\envs\\info_5612_project\\lib\\site-packages\\keras\\src\\engine\\training_v1.py:1181\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_sample_weight_modes(sample_weights\u001b[39m=\u001b[39msample_weights)\n\u001b[0;32m   1180\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_train_function()\n\u001b[1;32m-> 1181\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(ins)\n\u001b[0;32m   1183\u001b[0m \u001b[39mif\u001b[39;00m reset_metrics:\n\u001b[0;32m   1184\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_metrics()\n",
      "File \u001b[1;32mc:\\Users\\Eliza\\anaconda3\\envs\\info_5612_project\\lib\\site-packages\\keras\\src\\backend.py:4609\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4599\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4600\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   4601\u001b[0m     \u001b[39mor\u001b[39;00m feed_arrays \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4605\u001b[0m     \u001b[39mor\u001b[39;00m session \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\n\u001b[0;32m   4606\u001b[0m ):\n\u001b[0;32m   4607\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[1;32m-> 4609\u001b[0m fetched \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_callable_fn(\u001b[39m*\u001b[39;49marray_vals, run_metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_metadata)\n\u001b[0;32m   4610\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches) :])\n\u001b[0;32m   4611\u001b[0m output_structure \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   4612\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_structure,\n\u001b[0;32m   4613\u001b[0m     fetched[: \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)],\n\u001b[0;32m   4614\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   4615\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Eliza\\anaconda3\\envs\\info_5612_project\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1505\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1503\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1504\u001b[0m   run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1505\u001b[0m   ret \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39;49mTF_SessionRunCallable(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_session,\n\u001b[0;32m   1506\u001b[0m                                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle, args,\n\u001b[0;32m   1507\u001b[0m                                          run_metadata_ptr)\n\u001b[0;32m   1508\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[0;32m   1509\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model):\n",
    "    res_syn = model.run_eval(valid_news_file, valid_behaviors_file)\n",
    "    print(res_syn)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, data_path):\n",
    "    model_path = os.path.join(data_path, \"model\")\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model.model.save_weights(os.path.join(model_path, \"lstur_ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(model, data_path):\n",
    "    group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)\n",
    "    with open(os.path.join(data_path, 'prediction.txt'), 'w') as f:\n",
    "    for impr_index, preds in tqdm(zip(group_impr_indexes, group_preds)):\n",
    "        impr_index += 1\n",
    "        pred_rank = (np.argsort(np.argsort(preds)[::-1]) + 1).tolist()\n",
    "        pred_rank = '[' + ','.join([str(i) for i in pred_rank]) + ']'\n",
    "        f.write(' '.join([str(impr_index), pred_rank])+ '\\n')\n",
    "\n",
    "    f = zipfile.ZipFile(os.path.join(data_path, 'prediction.zip'), 'w', zipfile.ZIP_DEFLATED)\n",
    "    f.write(os.path.join(data_path, 'prediction.txt'), arcname='prediction.txt')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    user_ids = []\n",
    "    news_rec_lists = []\n",
    "    pred_prob = []\n",
    "    i = 0\n",
    "    group_impr_indexes, group_labels, group_preds = model.run_fast_eval(valid_news_file, valid_behaviors_file)\n",
    "    with open(valid_behaviors_file, 'r') as rd:\n",
    "            impr_index = 0\n",
    "            for line in rd:\n",
    "                uid, time, history, impr = line.strip(\"\\n\").split('\\t')[-4:]\n",
    "\n",
    "                impr_news = [i.split(\"-\")[0] for i in impr.split()]\n",
    "                user_ids.append(uid)\n",
    "                news_rec_lists.append(impr_news)\n",
    "                pred_prob.append(group_preds[i])\n",
    "                i+=1\n",
    "    user_rec_df = pd.DataFrame({'user_id' : user_ids, 'news_id': news_rec_lists, 'pred' : pred_prob})\n",
    "    user_rec_df = user_rec_df.explode(['news_id', 'pred'])\n",
    "    # need to sort; important to do that before selecting top k, either for diversity or mmr\n",
    "    # also this doesn't have true label...?\n",
    "    user_rec_df = user_rec_df.sort_values([\"user_id\", \"pred\"], ascending=False)\n",
    "    user_rec_df = user_rec_df.groupby(\"user_id\").agg({\"news_id\": list, \"pred\": list, \"label\": list})\n",
    "    return user_rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(arr):\n",
    "    return (arr - np.min(arr)) / (np.max(arr) - np.min(arr))\n",
    "    \n",
    "def normalize_df_for_mmr(df):\n",
    "    df_normalized = df.copy()\n",
    "    df_normalized['pred'] = df_normalized['pred'].apply(lambda x: normalize_array(x))\n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df()\n",
    "news_df = MMR.get_news_df()\n",
    "glove = MMR.load_glove()\n",
    "k = 5\n",
    "\n",
    "df_at_k = df.copy()\n",
    "df_at_k[\"news_id\"] = df[\"news_id\"].apply(lambda x: x[:k])\n",
    "\n",
    "print(f\"NDCG@{k} (baseline): {evaluation.calculate_ndcg_at_k(df_at_k, k)}\")\n",
    "print(f\"Diversity (baseline): {evaluation.diversity_eval(glove, news_df, df_at_k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After re-ranking via MMR\n",
    "Note that lamda = 0 means all diversity, no relevance, and lamda = 1 means all relevance, no diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamdas = [x/100.0 for x in range(0, 125, 25)]\n",
    "diversities = []\n",
    "ndcgs = []\n",
    "exploded_df = df.copy().reset_index().explode(['pred', 'label', 'news_id']) #split back into columns\n",
    "normalized_df = normalize_df_for_mmr(df)\n",
    "for i in lamdas:\n",
    "    print(f\"\\nReranking with lambda={i}...\")\n",
    "    mmr_rerank_data = MMR.mmr_all(glove, news_df, normalized_df, i, k)\n",
    "    mmr_rerank_df = pd.DataFrame.from_dict(mmr_rerank_data, orient=\"index\").reset_index()\n",
    "\n",
    "    diversity = evaluation.diversity_eval(glove, news_df, mmr_rerank_df)\n",
    "    print(f\"Diversity: {diversity}\")\n",
    "    diversities.append(diversity)\n",
    "\n",
    "    mmr_rerank_df = mmr_rerank_df.rename({\"index\": \"user_id\"}, axis=1)\n",
    "    split_df = mmr_rerank_df.set_index([\"user_id\"]).apply(lambda x: x.explode()).reset_index()\n",
    "    split_df = split_df.rename({\"pred\": \"mmr_pred\"}, axis=1)\n",
    "    mmr_labels = pd.merge(exploded_df, split_df, on=[\"user_id\", \"news_id\"], how=\"right\")\n",
    "    mmr_labels_lists = mmr_labels.groupby(\"user_id\").agg({\"label\": list, \"mmr_pred\": list})\n",
    "    mmr_labels_lists.rename(columns={\"mmr_pred\": \"pred\"}, inplace=True)\n",
    "    ndcg = evaluation.calculate_ndcg_at_k(mmr_labels_lists, k)\n",
    "    print(f\"NDCG@{k}: {ndcg}\")\n",
    "    ndcgs.append(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.graph_ndcg(ndcgs, lamdas, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation.graph_diversity(diversities, lamdas)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "3a9a0c422ff9f08d62211b9648017c63b0a26d2c935edc37ebb8453675d13bb5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
